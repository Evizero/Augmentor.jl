var documenterSearchIndex = {"docs":
[{"location":"operations/affine/flip/#Flip","page":"Flip","title":"Flip","text":"","category":"section"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"FlipX/FlipY can be used to flip the input image horizontally/vertically.","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, FlipX()),\n    augment(img_in, FlipY());\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"To perform a random flip, you can also pass the probablity to the constructor. For example, FlipX(0.5) flips the image with half chance.","category":"page"},{"location":"operations/affine/flip/#References","page":"Flip","title":"References","text":"","category":"section"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"FlipX\nFlipY","category":"page"},{"location":"operations/affine/flip/#Augmentor.FlipX","page":"Flip","title":"Augmentor.FlipX","text":"FlipX <: Augmentor.AffineOperation\n\nDescription\n\nReverses the x-order of each pixel row. Another way of describing it would be that it mirrors the image on the y-axis, or that it mirrors the image horizontally.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>FlipX(), 1-p=>NoOp()), where p denotes the probability of applying FlipX and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nFlipX()\n\nFlipX(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nFlipY, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, FlipX())\n2×2 Matrix{Int64}:\n 150  200\n   1   50\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/flip/#Augmentor.FlipY","page":"Flip","title":"Augmentor.FlipY","text":"FlipY <: Augmentor.AffineOperation\n\nDescription\n\nReverses the y-order of each pixel column. Another way of describing it would be that it mirrors the image on the x-axis, or that it mirrors the image vertically.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>FlipY(), 1-p=>NoOp()), where p denotes the probability of applying FlipY and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nFlipY()\n\nFlipY(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nFlipX, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, FlipY())\n2×2 Matrix{Int64}:\n  50    1\n 200  150\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/affine/scale/#Scale","page":"Scale","title":"Scale","text":"","category":"section"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Relatively resizing image","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"In the case that only a single scale factor is specified, the operation will assume that the intention is to scale all dimensions uniformly by that factor.","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"img_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Scale(0.8)),\n    augment(img_in, Scale(0.8, 1));\n\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"It is also possible to pass some abstract vector(s) to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Random.seed!(1337)\nimg_out = [augment(img_in, Scale(0.9:0.05:1.2)) for _ in 1:4]\nmosaicview(img_out...; fillvalue=colorant\"white\", nrow=2)","category":"page"},{"location":"operations/affine/scale/#References","page":"Scale","title":"References","text":"","category":"section"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Scale","category":"page"},{"location":"operations/affine/scale/#Augmentor.Scale","page":"Scale","title":"Augmentor.Scale","text":"Scale <: Augmentor.AffineOperation\n\nDescription\n\nMultiplies the image height and image width by the specified factors. This means that the size of the output image depends on the size of the input image.\n\nThe provided factors can either be numbers or vectors of numbers.\n\nIf numbers are provided, then the operation is deterministic and will always scale the input image with the same factors.\nIn the case vectors are provided, then each time the operation is applied a valid index is sampled and the elements corresponding to that index are used as scaling factors.\n\nThe scaling is performed relative to the image center, which can be useful when following the operation with CropNative.\n\nUsage\n\nScale(factors)\n\nScale(factors...)\n\nArguments\n\nfactors : NTuple or Vararg of Real or   AbstractVector that denote the scale factor(s) for each   array dimension. If only one variable is specified it is   assumed that height and width should be scaled by the same   factor(s).\n\nSee also\n\nZoom, Resize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# half the image size\naugment(img, Scale(0.5))\n\n# uniformly scale by a random factor from 1.2, 1.3, or 1.4\naugment(img, Scale([1.2, 1.3, 1.4]))\n\n# scale by either 0.5x0.7 or by 0.6x0.8\naugment(img, Scale([0.5, 0.6], [0.7, 0.8]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/cropsize/#CropSize","page":"CropSize","title":"CropSize","text":"","category":"section"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"Crop centered window to given size","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, CropSize(70, 70)) # crop out a square window\n\nmosaicview(img_in, img_out; nrow=1, npad=10)","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"RCropSize is a random version that randomly choose a crop center – not necessarily the center of the input image.","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"augment(img_in, CropSize(70, 70))\nnothing #hide","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"(Image: )","category":"page"},{"location":"operations/size/cropsize/#Reference","page":"CropSize","title":"Reference","text":"","category":"section"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"CropSize\nRCropSize","category":"page"},{"location":"operations/size/cropsize/#Augmentor.CropSize","page":"CropSize","title":"Augmentor.CropSize","text":"CropSize <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area of the specified pixel size around the center of the input image.\n\nFor example the operation CropSize(10, 50) would denote a crop for a rectangle of height 10 and width 50 around the center of the input image.\n\nUsage\n\nCropSize(size)\n\nCropSize(size...)\n\nArguments\n\nsize : NTuple or Vararg of Int that denote the   output size in pixel for each dimension.\n\nSee also\n\nCropRatio, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# cropped around center of rotated image\naugment(img, Rotate(45) |> CropSize(300, 400))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropsize/#Augmentor.RCropSize","page":"CropSize","title":"Augmentor.RCropSize","text":"RCropSize <: Augmentor.ImageOperation\n\nDescription\n\nCrops out an area of predefined size at some random position of the given image.\n\nFor example the operation RCropSize(128, 64) denotes a random crop with height 128 and width 64. RCropSize(64) denotes a square shaped crop of size 64.\n\nUsage\n\nRCropSize(height, width)\n\nRCropSize(width)\n\nArguments\n\nheight::Number : Height of cropped region\nwidth::Number : Width of cropped region\n\nSee also\n\nRCropRatio, CropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop a randomly placed square of size 100\naugment(img, RCropSize(100))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"indices/#Functions","page":"Indices","title":"Functions","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:function]","category":"page"},{"location":"indices/#Types","page":"Indices","title":"Types","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:type]","category":"page"},{"location":"interface/#High-level-Interface","page":"High-level Interface","title":"High-level Interface","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Integrating Augmentor into an existing project should in general not require any major changes to your code. In most cases it should break down to the three basic steps outlined below. We will spend the rest of this document investigating these in more detail.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Import Augmentor into the namespace of your program.\nusing Augmentor\nDefine a (stochastic) image processing pipeline by chaining the desired operations using |> and *.\njulia> pl = FlipX() * FlipY() |> Zoom(0.9:0.1:1.2) |> CropSize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Either: (50%) Flip the X axis. (50%) Flip the Y axis.\n 2.) Zoom by I ∈ {0.9×0.9, 1.0×1.0, 1.1×1.1, 1.2×1.2}\n 3.) Crop a 64×64 window around the center\nApply the pipeline to the existing image or set of images.\nimg_processed = augment(img_original, pl)","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Depending on the complexity of your problem, you may want to iterate between step 2. and 3. to identify an appropriate pipeline. Take a look at the Elastic Distortions Tutorial for an example of how such an iterative process could look like.","category":"page"},{"location":"interface/#pipeline","page":"High-level Interface","title":"Defining a Pipeline","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"In Augmentor, a (stochastic) image-processing pipeline can be understood as a sequence of operations, for which the parameters can (but need not) be random variables. What that essentially means is that the user explicitly specifies which image operation to perform in what order. A complete list of available operations can be found at Supported Operations.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"To start off with a simple example, let us assume that we want to first rotate our image(s) counter-clockwise by 14°, then crop them down to the biggest possible square, and lastly resize the image(s) to a fixed size of 64 by 64 pixel. Such a pipeline would be defined as follows:","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = Rotate(14) |> CropRatio(1) |> Resize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Rotate 14 degree\n 2.) Crop to 1:1 aspect ratio\n 3.) Resize to 64×64","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Notice that in the example above there is no room for randomness. In other words, the same input image would always result in the same output image given that pipeline. If we wish for more variation we can do so by using a vector as our parameters, instead of a single number.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"note: Note\nIn this subsection we will focus only on how to define a pipeline, without actually thinking too much about how to apply that pipeline to an actual image. The later will be the main topic of the rest of this document.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Say we wish to adapt our pipeline such that the rotation is a little more random. More specifically, lets say we want our image to be rotated by either -10°, -5°, 5°, 10°, or not at all. Other than that change we will leave the rest of the pipeline as is.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = Rotate([-10,-5,0,5,10]) |> CropRatio(1) |> Resize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Rotate by θ ∈ [-10, -5, 0, 5, 10] degree\n 2.) Crop to 1:1 aspect ratio\n 3.) Resize to 64×64","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Variation in the parameters is only one of the two main ways to introduce randomness to our pipeline. Additionally, one can specify that an operation should be sampled randomly from a chosen set of operations . This can be accomplished using a utility operation called Either, which has its own convenience syntax.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"As an example, let us assume we wish to first either mirror our image(s) horizontally, or vertically, or not at all, and then crop it down to a size of 100 by 100 pixel around the image's center. We can specify the \"either\" using the * operator.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = FlipX() * FlipY() * NoOp() |> CropSize(100,100)\n2-step Augmentor.ImmutablePipeline:\n 1.) Either: (33%) Flip the X axis. (33%) Flip the Y axis. (33%) No operation.\n 2.) Crop a 100×100 window around the center","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"It is also possible to specify the odds of for such an \"either\". For example we may want the NoOp to be twice as likely as either of the mirroring options.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = (1=>FlipX()) * (1=>FlipY()) * (2=>NoOp()) |> CropSize(100,100)\n2-step Augmentor.ImmutablePipeline:\n 1.) Either: (25%) Flip the X axis. (25%) Flip the Y axis. (50%) No operation.\n 2.) Crop a 100×100 window around the center","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Now that we know how to define a pipeline, let us think about how to apply it to an image or a set of images.","category":"page"},{"location":"interface/#The-design-behind-operation-types","page":"High-level Interface","title":"The design behind operation types","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"The purpose of an operation is to simply serve as a \"dumb placeholder\" to specify the intent and parameters of the desired transformation. What that means is that a pipeline of operations can be thought of as a list of instructions (a cookbook of sorts), that Augmentor uses internally to construct the required code that implements the desired behaviour in the most efficient way it can.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"The way an operation is implemented depends on the rest of the specified pipeline. For example, Augmentor knows three different ways to implement the behaviour of the operation Rotate90 and will choose the one that best coincides with the other operations of the pipeline and their concrete order.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Call the function rotl90 of Julia's base library, which makes use of the fact that a 90 degree rotation can be implemented very efficiently. While by itself this is the fastest way to compute the result, this function is \"eager\" and will allocate a new array. If Rotate90 is followed by another operation this may not be the best choice, since it will cause a temporary image that is later discarded.\nCreate a SubArray of a PermutedDimsArray. This is more or less a lazy version of rotl90 that makes use of the fact that a 90 degree rotation can be described 1-to-1 using just the original pixels. By itself this strategy is slower than rotl90, but if it is followed by an operation such as Crop or CropSize it can be significantly faster. The reason for this is that it avoids the computation of unused pixels and also any allocation of temporary memory. The computation overhead per output pixel, while small, grows linearly with the number of chained operations.\nCreate an AffineMap using a rotation matrix that describes a 90 degree rotation around the center of the image. This will result in a lazy transformation of the original image that is further compose-able with other AffineMap. This is the slowest available strategy, unless multiple affine operations are chained together. If that is the case, then chaining the operations can be reduced to composing the tiny affine maps instead. This effectively fuses multiple operations into a single operation for which the computation overhead per output pixel remains approximately constant in respect to the number of chained operations.","category":"page"},{"location":"interface/#Loading-the-Example-Image","page":"High-level Interface","title":"Loading the Example Image","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Augmentor ships with a custom example image, which was specifically designed for visualizing augmentation effects. It can be accessed by calling the function testpattern(). That said, doing so explicitly should rarely be necessary in practice, because most high-level functions will default to using testpattern() if no other image is specified.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"testpattern","category":"page"},{"location":"interface/#Augmentor.testpattern","page":"High-level Interface","title":"Augmentor.testpattern","text":"testpattern([T=RGBA{N0f8}]; ratio=1.0) -> Matrix{RGBA{N0f8}}\n\nLoad and return the provided 300x400 test image. Additional args and kwargs are passed to imresize.\n\nThe returned image was specifically designed to be informative about the effects of the applied augmentation operations. It is thus well suited to prototype an augmentation pipeline, because it makes it easy to see what kind of effects one can achieve with it.\n\n\n\n\n\n","category":"function"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"using Augmentor\nimg = testpattern()\nusing Images; # hide\nsave(joinpath(\"assets\",\"big_pattern.png\"), img); # hide\nnothing # hide","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"(Image: testpattern)","category":"page"},{"location":"interface/#Augmenting-an-Image","page":"High-level Interface","title":"Augmenting an Image","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Once a pipeline is constructed it can be applied to an image (i.e. AbstractArray{<:ColorTypes.Colorant}), or even just to an array of numbers (i.e. AbstractArray{<:Number}), using the function augment.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augment","category":"page"},{"location":"interface/#Augmentor.augment","page":"High-level Interface","title":"Augmentor.augment","text":"augment([img], pipeline) -> out\n\nApply the operations of the given pipeline sequentially to the given image img and return the resulting image out.\n\njulia> img = testpattern();\n\njulia> out = augment(img, FlipX() |> FlipY())\n3×2 Array{Gray{N0f8},2}:\n[...]\n\nThe parameter img can either be a single image, or a tuple of multiple images. In case img is a tuple of images, its elements will be assumed to be conceptually connected. Consequently, all images in the tuple will take the exact same path through the pipeline; even when randomness is involved. This is useful for the purpose of image segmentation, for which the input and output are both images that need to be transformed exactly the same way.\n\nimg1 = testpattern()\nimg2 = Gray.(testpattern())\nout1, out2 = augment((img1, img2), FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\nimg = testpattern()\naugment(img, FlipX() |> FlipY())\naugment(img, (FlipX(), FlipY()))\naugment(img, FlipX())\n\nIf img is omitted, Augmentor will use the augmentation test image provided by the function testpattern as the input image.\n\naugment(FlipX())\n\n\n\n\n\n","category":"function"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"We also provide a mutating version of augment that writes the output into preallocated memory. While this function avoids allocation, it does have the caveat that the size of the output image must be known beforehand (and thus must not be random).","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augment!","category":"page"},{"location":"interface/#Augmentor.augment!","page":"High-level Interface","title":"Augmentor.augment!","text":"augment!(out, img, pipeline) -> out\n\nApply the operations of the given pipeline sequentially to the image img and write the resulting image into the preallocated parameter out. For convenience out is also the function's return-value.\n\nimg = testpattern()\nout = similar(img)\naugment!(out, img, FlipX() |> FlipY())\n\nThe parameter img can either be a single image, or a tuple of multiple images. In case img is a tuple of images, the parameter out has to be a tuple of the same length and ordering. See augment for more information.\n\nimgs = (testpattern(), Gray.(testpattern()))\nouts = (similar(imgs[1]), similar(imgs[2]))\naugment!(outs, imgs, FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\nimg = testpattern()\nout = similar(img)\naugment!(out, img, FlipX() |> FlipY())\naugment!(out, img, (FlipX(), FlipY()))\naugment!(out, img, FlipX())\n\n\n\n\n\n","category":"function"},{"location":"interface/#Augmenting-Image-Batches","page":"High-level Interface","title":"Augmenting Image Batches","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"In most machine learning scenarios we will want to process a whole batch of images at once, instead of a single image at a time. For this reason we provide the function augmentbatch!, which also supports multi-threading.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augmentbatch!","category":"page"},{"location":"interface/#Augmentor.augmentbatch!","page":"High-level Interface","title":"Augmentor.augmentbatch!","text":"augmentbatch!([resource], outs, imgs, pipeline, [obsdim]) -> outs\n\nApply the operations of the given pipeline to the images in imgs and write the resulting images into outs.\n\nBoth outs and imgs have to contain the same number of images. Each of these two variables can either be in the form of a higher dimensional array, in the form of a vector of arrays for which each vector element denotes an image.\n\n# create five example observations of size 3x3\nimgs = rand(3,3,5)\n# create output arrays of appropriate shape\nouts = similar(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\n\nIf one (or both) of the two parameters outs and imgs is a higher dimensional array, then the optional parameter obsdim can be used specify which dimension denotes the observations (defaults to ObsDim.Last()),\n\n# create five example observations of size 3x3\nimgs = rand(5,3,3)\n# create output arrays of appropriate shape\nouts = similar(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY(), ObsDim.First())\n\nSimilar to augment!, it is also allowed for outs and imgs to both be tuples of the same length. If that is the case, then each tuple element can be in any of the forms listed above. This is useful for tasks such as image segmentation, where each observations is made up of more than one image.\n\n# create five example observations where each observation is\n# made up of two conceptually linked 3x3 arrays\nimgs = (rand(3,3,5), rand(3,3,5))\n# create output arrays of appropriate shape\nouts = similar.(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\naugmentbatch!(outs, imgs, (FlipX(), FlipY()))\naugmentbatch!(outs, imgs, FlipX())\n\nThe optional first parameter resource can either be CPU1() (default) or CPUThreads(). In the later case the images will be augmented in parallel. For this to make sense make sure that the environment variable JULIA_NUM_THREADS is set to a reasonable number so that Threads.nthreads() is greater than 1.\n\n# transform the batch of images in parallel using multithreading\naugmentbatch!(CPUThreads(), outs, imgs, FlipX() |> FlipY())\n\n\n\n\n\n","category":"function"},{"location":"images/#Working-with-Images-in-Julia","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"The Julia language provides a rich syntax as well as large set of highly-optimized functionality for working with (multi-dimensional) arrays of what is known as \"bit types\" or compositions of such. Because of this, the language lends itself particularly well to the fairly simple idea of treating images as just plain arrays. Even though this may sound as a rather tedious low-level approach, Julia makes it possible to still allow for powerful abstraction layers without the loss of generality that usually comes with that. This is accomplished with help of Julia's flexible type system and multiple dispatch (both of which are beyond the scope of this tutorial).","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"While the images-are-arrays-approach makes working with images in Julia very performant, it has also been source of confusion to new community members. This beginner's guide is an attempt to provide a step-by-step overview of how pixel data is handled in Julia. To get a more detailed explanation on some particular concept involved, please take a look at the documentation of the JuliaImages ecosystem.","category":"page"},{"location":"images/#Multi-dimensional-Arrays","page":"Working with Images in Julia","title":"Multi-dimensional Arrays","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"To wrap our heads around Julia's array-based treatment of images, we first need to understand what Julia arrays are and how we can work with them.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"note: Note\nThis section is only intended provide a simplified and thus partial overview of Julia's arrays capabilities in order to gain some intuition about pixel data. For a more detailed treatment of the topic please have a look at the official documentation","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Whenever we work with an Array in which the elements are bit-types (e.g. Int64, Float32, UInt8, etc), we can think of the array as a continuous block of memory. This is useful for many different reasons, such as cache locality and interacting with external libraries.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"The same block of memory can be interpreted in a number of ways. Consider the following example in which we allocate a vector (i.e. a one dimensional array) of UInt8 (i.e. bytes) with some ordered example values ranging from 1 to 6. We will think of this as our physical memory block, since it is a pretty close representation.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> memory = [0x1, 0x2, 0x3, 0x4, 0x5, 0x6]\n6-element Vector{UInt8}:\n 0x01\n 0x02\n 0x03\n 0x04\n 0x05\n 0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"The same block of memory could also be interpreted differently. For example we could think of this as a matrix with 3 rows and 2 columns instead (or even the other way around). The function reshape allows us to do just that","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> A = reshape(memory, (3, 2))\n3×2 Matrix{UInt8}:\n 0x01  0x04\n 0x02  0x05\n 0x03  0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Note how we specified the number of rows first. This is because the Julia language follows the column-major convention for multi dimensional arrays. What this means can be observed when we compare our new matrix A with the initial vector memory and look at the element layout. Both variables are using the same underlying memory (i.e the value 0x01 is physically stored right next to the value 0x02 in our example, while 0x01 and 0x04 are quite far apart even though the matrix interpretation makes it look like they are neighbors; which they are not).","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"tip: Tip\nA quick and dirty way to check if two variables are representing the same block of memory is by comparing the output of pointer(myvariable). Note, however, that technically this only tells you where a variable starts in memory and thus has its limitations.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"This idea can also be generalized for higher dimensions. For example we can think of this as a 3D array as well.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> reshape(memory, (3, 1, 2))\n3×1×2 Array{UInt8, 3}:\n[:, :, 1] =\n 0x01\n 0x02\n 0x03\n\n[:, :, 2] =\n 0x04\n 0x05\n 0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"If you take a closer look at the dimension sizes, you can see that all we did in that example was add a new dimension of size 1, while not changing the other numbers. In fact we can add any number of practically empty dimensions, otherwise known as singleton dimensions.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> reshape(memory, (3,1,1,1,2))\n3×1×1×1×2 Array{UInt8, 5}:\n[:, :, 1, 1, 1] =\n 0x01\n 0x02\n 0x03\n\n[:, :, 1, 1, 2] =\n 0x04\n 0x05\n 0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"This is a useful property to have when we are confronted with greyscale datasets that do not have a color channel, yet we still want to work with a library that expects the images to have one.","category":"page"},{"location":"images/#Vertical-Major-vs-Horizontal-Major","page":"Working with Images in Julia","title":"Vertical-Major vs Horizontal-Major","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"There are a number of different conventions for how to store image data into a binary format. The first question one has to address is the order in which the image dimensions are transcribed.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"We have seen before that Julia follows the column-major convention for its arrays, which for images would lead to the corresponding convention of being vertical-major. In the image domain, however, it is fairly common to store the pixels in a horizontal-major layout. In other words, horizontal-major means that images are stored in memory (or file) one pixel row after the other.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"In most cases, when working within the JuliaImages ecosystem, the images should already be in the Julia-native column major layout. If for some reason that is not the case there are two possible ways to convert the image to that format.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> At = collect(reshape(memory, (3,2))') # \"row-major\" layout\n2×3 Matrix{UInt8}:\n 0x01  0x02  0x03\n 0x04  0x05  0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"The first way to alter the pixel order is by using the function Base.permutedims. In contrast to what we have seen before, this function will allocate a new array and copy the values in the appropriate manner.\njulia> B = permutedims(At, (2,1))\n3×2 Matrix{UInt8}:\n 0x01  0x04\n 0x02  0x05\n 0x03  0x06\nThe second way is using Base.PermutedDimsArray which results in a lazy view that does not allocate a new array but instead only computes the correct values when queried.\njulia> C = PermutedDimsArray(At, (2,1))\n3×2 PermutedDimsArray(::Matrix{UInt8}, (2, 1)) with eltype UInt8:\n 0x01  0x04\n 0x02  0x05\n 0x03  0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Either way, it is in general a good idea to make sure that the array one is working with ends up in a column-major layout.","category":"page"},{"location":"images/#Reinterpreting-Elements","page":"Working with Images in Julia","title":"Reinterpreting Elements","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Up to this point, all we talked about was how to reinterpreting or permuting the dimensional layout of some continuous memory block. If you look at the examples above you will see that all the arrays have elements of type UInt8, which just means that each element is represented by a single byte in memory.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Knowing all this, we can now take the idea a step further and think about reinterpreting the element types of the array. Let us consider our original vector memory again.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> memory = [0x1, 0x2, 0x3, 0x4, 0x5, 0x6]\n6-element Vector{UInt8}:\n 0x01\n 0x02\n 0x03\n 0x04\n 0x05\n 0x06","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Note how each byte is thought of as an individual element. One thing we could do instead, is think of this memory block as a vector of 3 UInt16 elements.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> reinterpret(UInt16, memory)\n3-element reinterpret(UInt16, ::Vector{UInt8}):\n 0x0201\n 0x0403\n 0x0605","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Pay attention to where our original bytes ended up. In contrast to just rearranging elements as we did before, we ended up with significantly different element values. One may ask why it would ever be practical to reinterpret a memory block like this. The one word answer to this is Colors! As we will see in the remainder of this tutorial, it turns out to be a very useful thing to do when your arrays represent pixel data.","category":"page"},{"location":"images/#Introduction-to-Color-Models","page":"Working with Images in Julia","title":"Introduction to Color Models","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"As we discussed before, there are a various number of conventions on how to store pixel data into a binary format. That is not only true for dimension priority, but also for color information.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"One way color information can differ is in the color model in which they are described in. Two famous examples for color models are RGB and HSV. They essentially define how colors are conceptually made up in terms of some components. Additionally, one can decide on how many bits to use to describe each color component. By doing so one defines the available color depth.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Before we look into using the actual implementation of Julia's color models, let us prototype our own imperfect toy model in order to get a better understanding of what is happening under the hood.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"# define our toy color model\nstruct MyRGB\n    r::UInt8\n    b::UInt8\n    g::UInt8\nend","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Note how we defined our new toy color model as struct. Because of this and the fact that all its components are bit types (in this case UInt8), any instantiation of our new type will be represented as a continuous block of memory as well.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"We can now apply our color model to our memory vector from above, and interpret the underlying memory as a vector of to MyRGB values instead.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> reinterpret(MyRGB, memory)\n2-element Vector{MyRGB}:\n MyRGB(0x01,0x02,0x03)\n MyRGB(0x04,0x05,0x06)","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Similar to the UInt16 example, we now group neighboring bytes into larger units (namely MyRGB). In contrast to the UInt16 example we are still able to access the individual components underneath. This simple toy color model already allows us to do a lot of useful things. We could define functions that work on MyRGB values in a color-space appropriate fashion. We could also define other color models and implement function to convert between them.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"However, our little toy color model is not yet optimal. For example it hard-codes a predefined color depth of 24 bit. We may have use-cases where we need a richer color space. One thing we could do to achieve that would be to introduce a new type in similar fashion. Still, because they have a different range of available numbers per channel (because they have a different amount of bits per channel), we would have to write a lot of specialized code to be able to appropriately handle all color models and depth.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Luckily, the creators of ColorTypes.jl went a with a more generic strategy: Using parameterized types and fixed point numbers.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"tip: Tip\nIf you are interested in how various color models are actually designed and/or implemented in Julia, you can take a look at the ColorTypes.jl package.","category":"page"},{"location":"images/#Fixed-Point-Numbers","page":"Working with Images in Julia","title":"Fixed Point Numbers","text":"","category":"section"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"The idea behind using fixed point numbers for each color component is fairly simple. No matter how many bits a component is made up of, we always want the largest possible value of the component to be equal to 1.0 and the smallest possible value to be equal to 0. Of course, the amount of possible intermediate numbers still depends on the number of underlying bits in the memory, but that is not much of an issue.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> using ImageCore; # ImageCore reexports FixedPointNumbers and Colors\n\njulia> reinterpret(N0f8, 0xFF)\n1.0N0f8\n\njulia> reinterpret(N0f16, 0xFFFF)\n1.0N0f16","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Not only does this allow for simple conversion between different color depths, it also allows us to implement generic algorithms, that are completely agnostic to the utilized color depth.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"It is worth pointing out again, that we get all these goodies without actually changing or copying the original memory block. Remember how during this whole tutorial we have only changed the interpretation of some underlying memory, and have not had the need to copy any data so far.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"tip: Tip\nFor pixel data we are mainly interested in unsigned fixed point numbers, but there are others too. Check out the package FixedPointNumbers.jl for more information on fixed point numbers in general.","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Let us now leave our toy model behind and use the actual implementation of RGB on our example vector memory. With the first command we will interpret our data as two pixels with 8 bit per color channel, and with the second command as a single pixel of 16 bit per color channel","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"julia> reinterpret(RGB{N0f8}, memory)\n2-element reinterpret(RGB{N0f8}, ::Vector{UInt8}):\n RGB{N0f8}(0.004,0.008,0.012)\n RGB{N0f8}(0.016,0.02,0.024)\n\njulia> reinterpret(RGB{N0f16}, memory)\n1-element reinterpret(RGB{N0f16}, ::Vector{UInt8}):\n RGB{N0f16}(0.00783,0.01567,0.02351)","category":"page"},{"location":"images/","page":"Working with Images in Julia","title":"Working with Images in Julia","text":"Note how the values are now interpreted as floating point numbers.","category":"page"},{"location":"examples/#tutorials","page":"Tutorials","title":"Tutorials","text":"","category":"section"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"Here we provide several tutorials that you may want to follow up and see how Augmentor is used in practice.","category":"page"},{"location":"examples/#Examples","page":"Tutorials","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"<div class=\"list-card-section\">","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"<div class=\"list-card\">\n<table>\n  <td valign=\"bottom\"><div class=\"list-card-cover\">","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"(Image: list-card-cover-image)","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"  </div></td>\n  <td><div class=\"list-card-text\">","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"Elastic distortion to MNIST images","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"</div>\n    <div class=\"list-card-description\">","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"In this example we are going to use Augmentor on the famous MNIST database of handwritten digits [MNIST1998] to reproduce the elastic distortions discussed in [SIMARD2003].","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"    </div>\n  </td>\n</tbody></table>\n</div>","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"</div>","category":"page"},{"location":"examples/#References","page":"Tutorials","title":"References","text":"","category":"section"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"[MNIST1998]: LeCun, Yan, Corinna Cortes, Christopher J.C. Burges. \"The MNIST database of handwritten digits\" Website. 1998.","category":"page"},{"location":"examples/","page":"Tutorials","title":"Tutorials","text":"[SIMARD2003]: Simard, Patrice Y., David Steinkraus, and John C. Platt. \"Best practices for convolutional neural networks applied to visual document analysis.\" ICDAR. Vol. 3. 2003.","category":"page"},{"location":"operations/#operations","page":"Supported Operations","title":"Supported Operations","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Augmentor provides a wide variety of build-in image operations. This page provides an overview of all exported operations organized by their main category. These categories are chosen because they serve some practical purpose. For example Affine Operations allow for a special optimization under the hood when chained together.","category":"page"},{"location":"operations/#Affine-Transformations","page":"Supported Operations","title":"Affine Transformations","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"A sizeable amount of the provided operations fall under the category of affine transformations. As such, they can be described using what is known as an affine map, which are inherently compose-able if chained together. However, utilizing such a affine formulation requires (costly) interpolation, which may not always be needed to achieve the desired effect. For that reason do some of the operations below also provide a special purpose implementation to produce their specified result. Those are usually preferred over the affine formulation if sensible considering the complete pipeline.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"flip the input image horizontally or vertically","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Flip","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"rotate image anticlockwise","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Rotate","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"shear the input image horizontally or vertically","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Shear","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Relatively resizing image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Scale","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Set the static size of the image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Resize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Scale without resize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Zoom","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Distortions","page":"Supported Operations","title":"Distortions","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Aside from affine transformations, Augmentor also provides functionality for performing a variety of distortions. These types of operations usually provide a much larger distribution of possible output images.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Smoothed random distortion","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"ElasticDistortion","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Color-adjustments","page":"Supported Operations","title":"Color adjustments","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Adjust contrast and brightness of an image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"ColorJitter","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Blurring","page":"Supported Operations","title":"Blurring","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"blur the input image using a gaussian kernel","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"GaussianBlur","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Resizing-and-Subsetting","page":"Supported Operations","title":"Resizing and Subsetting","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"The process of cropping is useful to discard parts of the input image. To provide this functionality lazily, applying a crop introduces a layer of representation called a \"view\" or SubArray. This is different yet compatible with how affine operations or other special purpose implementations work. This means that chaining a crop with some affine operation is perfectly fine if done sequentially. However, it is generally not advised to combine affine operations with crop operations within an Either block. Doing that would force the Either to trigger the eager computation of its branches in order to preserve type-stability.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Subset image using Crop and CropNative","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop centered window to given size","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"CropSize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop centered window to fit given aspect ratio","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"CropRatio","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Misc","page":"Supported Operations","title":"Misc","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"a set of commonly used basic operations that wrapped by Augmentor","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Colorant conversion and channel layout","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card\">\n<div class=\"card-cover\">\n<div class=\"card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"a set of helper opeartions that may be useful when compositing more complex augmentation workflow","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Composition utilities","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/affine/zoom/#Zoom","page":"Zoom","title":"Zoom","text":"","category":"section"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Scale without resize","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"In the case that only a single Zoom factor is specified, the operation will assume that the intention is to Zoom all dimensions uniformly by that factor.","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"img_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Zoom(1.3)),\n    augment(img_in, Zoom(1.3, 1));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"It is also possible to pass some abstract vector(s) to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Random.seed!(1337)\nimg_out = [augment(img_in, Zoom(0.9:0.05:1.2)) for _ in 1:4]\n\nmosaicview(img_out...; nrow=2)","category":"page"},{"location":"operations/affine/zoom/#References","page":"Zoom","title":"References","text":"","category":"section"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Zoom","category":"page"},{"location":"operations/affine/zoom/#Augmentor.Zoom","page":"Zoom","title":"Augmentor.Zoom","text":"Zoom <: Augmentor.ImageOperation\n\nDescription\n\nScales the image height and image width by the specified factors, but crops the image such that the original size is preserved.\n\nThe provided factors can either be numbers or vectors of numbers.\n\nIf numbers are provided, then the operation is deterministic and will always scale the input image with the same factors.\nIn the case vectors are provided, then each time the operation is applied a valid index is sampled and the elements corresponding to that index are used as scaling factors.\n\nIn contrast to Scale the size of the output image is the same as the size of the input image, while the content is scaled the same way. The same effect could be achieved by following a Scale with a CropSize, with the caveat that one would need to know the exact size of the input image before-hand.\n\nUsage\n\nZoom(factors)\n\nZoom(factors...)\n\nArguments\n\nfactors : NTuple or Vararg of Real or   AbstractVector that denote the scale factor(s) for each   array dimension. If only one variable is specified it is   assumed that height and width should be scaled by the same   factor(s).\n\nSee also\n\nScale, Resize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# half the image size\naugment(img, Zoom(0.5))\n\n# uniformly scale by a random factor from 1.2, 1.3, or 1.4\naugment(img, Zoom([1.2, 1.3, 1.4]))\n\n# scale by either 0.5x0.7 or by 0.6x0.8\naugment(img, Zoom([0.5, 0.6], [0.7, 0.8]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"gettingstarted/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"In this section we will provide a condensed overview of the package. In order to keep this overview concise, we will not discuss any background information or theory on the losses here in detail.","category":"page"},{"location":"gettingstarted/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To install Augmentor.jl, start up Julia and type the following code-snipped into the REPL. It makes use of the native Julia package manger.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.add(\"Augmentor\")","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Additionally, for example if you encounter any sudden issues, or in the case you would like to contribute to the package, you can manually choose to be on the latest (untagged) version.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.develop(\"Augmentor\")","category":"page"},{"location":"gettingstarted/#Example","page":"Getting Started","title":"Example","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The following code snippet shows how a stochastic augmentation pipeline can be specified using simple building blocks that we call \"operations\". In order to give the example some meaning, we will use a real medical image from the publicly available ISIC archive as input. The concrete image can be downloaded here using their Web API.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> using Augmentor, ISICArchive\n\njulia> img = get(ImageThumbnailRequest(id = \"5592ac599fc3c13155a57a85\"))\n169×256 Array{RGB{N0f8},2}:\n[...]\n\njulia> pl = Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()) |>\n            Rotate(0:360) |>\n            ShearX(-5:5) * ShearY(-5:5) |>\n            CropSize(165, 165) |>\n            Zoom(1:0.05:1.2) |>\n            Resize(64, 64)\n6-step Augmentor.ImmutablePipeline:\n 1.) Either: (25%) Flip the X axis. (25%) Flip the Y axis. (50%) No operation.\n 2.) Rotate by θ ∈ 0:360 degree\n 3.) Either: (50%) ShearX by ϕ ∈ -5:5 degree. (50%) ShearY by ψ ∈ -5:5 degree.\n 4.) Crop a 165×165 window around the center\n 5.) Zoom by I ∈ {1.0×1.0, 1.05×1.05, 1.1×1.1, 1.15×1.15, 1.2×1.2}\n 6.) Resize to 64×64\n\njulia> img_new = augment(img, pl)\n64×64 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using Augmentor, ISICArchive\nusing ImageCore, ImageMagick\nusing Random\n\nimg = get(ImageThumbnailRequest(id = \"5592ac599fc3c13155a57a85\"))\n\npl = Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()) |>\n     Rotate(0:360) |>\n     ShearX(-5:5) * ShearY(-5:5) |>\n     CropSize(165, 165) |>\n     Zoom(1:0.05:1.2) |>\n     Resize(64, 64)\n\n# modified from operations/assets/gif.jl\nfunction make_gif(img, pl, num_sample; post_op=identity, random_seed=1337)\n    Random.seed!(random_seed)\n\n    fillvalue = oneunit(eltype(img))\n    frames = sym_paddedviews(\n        fillvalue,\n        post_op(img),\n        [post_op(augment(img, pl)) for _ in 1:num_sample-1]...\n    )\n    cat(frames..., dims=3)\nend\n\nImageMagick.save(joinpath(\"assets\",\"isic_in.png\"), img)\npreview = make_gif(img, pl, 10)[:, :, 2:end]\nImageMagick.save(joinpath(\"assets\", \"isic_out.gif\"), preview; fps=2)\n\nnothing","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The function augment will generate a single augmented image from the given input image and pipeline. To visualize the effect we compiled a few resulting output images into a GIF.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Input (img)  Output (img_new)\n(Image: input) → (Image: output)","category":"page"},{"location":"gettingstarted/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To get help on specific functionality you can either look up the information here, or if you prefer you can make use of Julia's native doc-system. The following example shows how to get additional information on augment within Julia's REPL:","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"?augment","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you find yourself stuck or have other questions concerning the package you can find us at gitter or the Machine Learning domain on discourse.julialang.org","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Julia ML on Gitter\nMachine Learning on Julialang","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you encounter a bug or would like to participate in the development of this package come find us on Github.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Evizero/Augmentor.jl","category":"page"},{"location":"operations/affine/shear/#Shear","page":"Shear","title":"Shear","text":"","category":"section"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"ShearX/ShearY can be used to shear the input image horizontally/vertically. The input to the constructor can be a scalar or a vector. In the case of a vector, the transformation will be a stochastic process.","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\nRandom.seed!(0)\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    # deterministic transformation\n    augment(img_in, ShearX(20)),\n    augment(img_in, ShearY(20)),\n\n    # random transformation\n    augment(img_in, ShearX(-20:20)),\n    augment(img_in, ShearY(-20:20));\n\n    fillvalue=colorant\"white\", nrow=2, npad=10\n)","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"Note that the output image size will be changed after transformation, CropNative can be particalually useful to preserve the image size.","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"mosaicview(\n    augment(img_in, ShearX(10)),\n    augment(img_in, ShearX(10) |> CropNative(axes(img_in)));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/shear/#References","page":"Shear","title":"References","text":"","category":"section"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"ShearX\nShearY","category":"page"},{"location":"operations/affine/shear/#Augmentor.ShearX","page":"Shear","title":"Augmentor.ShearX","text":"ShearX <: Augmentor.AffineOperation\n\nDescription\n\nShear the image horizontally for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIt will always perform the transformation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nShearX(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the shearing angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nShearY, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# shear horizontally exactly 5 degree\naugment(img, ShearX(5))\n\n# shear horizontally between 10 and 20 degree to the right\naugment(img, ShearX(10:20))\n\n# shear horizontally one of the five specified degrees\naugment(img, ShearX([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/shear/#Augmentor.ShearY","page":"Shear","title":"Augmentor.ShearY","text":"ShearY <: Augmentor.AffineOperation\n\nDescription\n\nShear the image vertically for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIt will always perform the transformation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nShearY(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the shearing angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nShearX, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# shear vertically exactly 5 degree\naugment(img, ShearY(5))\n\n# shear vertically between 10 and 20 degree upwards\naugment(img, ShearY(10:20))\n\n# shear vertically one of the five specified degrees\naugment(img, ShearY([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/crop/#Crop","page":"Crop","title":"Crop","text":"","category":"section"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Subset image using Crop and CropNative","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"using Augmentor\nusing ImageShow, ImageCore\nusing OffsetArrays\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, Crop(20:75,25:120))\n\nmosaicview(img_in, img_out; fillvalue=colorant\"white\", nrow=1)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"If the input image is plain arrays without offset indices, then Crop and CropNative is equivalent.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"augment(img_in, Crop(20:75,25:120)) == augment(img_in, CropNative(20:75,25:120))","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Whether you should use Crop or CropNative depends on if you want to take the index offset of the input image into consideration.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"imgo_in = OffsetArray(img_in, -50, -50)\nimgo_out = augment(imgo_in, Crop(20:75,25:120))\nimgo_out_native = augment(imgo_in, CropNative(20:75,25:120))\n\n(\n    imgo_in[(first.(axes(imgo_in)) .+ (20, 25))...] == imgo_out[1, 1],\n    imgo_in[20, 25] == imgo_out_native[1, 1]\n)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"A typical scenario that you may want to use CropNative is when you have affine operations, e.g., Rotate and ShearX.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"mosaicview(\n    augment(img_in, Rotate(30) |> Crop(axes(img_in))),\n    augment(img_in, Rotate(30) |> CropNative(axes(img_in))),\n\n    augment(img_in, ShearX(10) |> Crop(axes(img_in))),\n    augment(img_in, ShearX(10) |> CropNative(axes(img_in)));\n\n    fillvalue=colorant\"white\", rowmajor=true, nrow=2, npad=10\n)","category":"page"},{"location":"operations/size/crop/#Reference","page":"Crop","title":"Reference","text":"","category":"section"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Crop\nCropNative","category":"page"},{"location":"operations/size/crop/#Augmentor.Crop","page":"Crop","title":"Augmentor.Crop","text":"Crop <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area denoted by the specified pixel ranges.\n\nFor example the operation Crop(5:100, 2:10) would denote a crop for the rectangle that starts at x=2 and y=5 in the top left corner and ends at x=10 and y=100 in the bottom right corner. As we can see the y-axis is specified first, because that is how the image is stored in an array. Thus the order of the provided axes ranges needs to reflect the order of the array dimensions.\n\nUsage\n\nCrop(indices)\n\nCrop(indices...)\n\nArguments\n\nindices : NTuple or Vararg of UnitRange that denote   the cropping range for each array dimension. This is very   similar to how the axes for view are specified.\n\nSee also\n\nCropNative, CropSize, CropRatio, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> augment(img, Crop(1:30, 361:400)) # crop upper right corner\n30×40 Array{RGBA{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/size/crop/#Augmentor.CropNative","page":"Crop","title":"Augmentor.CropNative","text":"CropNative <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area denoted by the specified pixel ranges.\n\nFor example the operation CropNative(5:100, 2:10) would denote a crop for the rectangle that starts at x=2 and y=5 in the top left corner of native space and ends at x=10 and y=100 in the bottom right corner of native space.\n\nIn contrast to Crop, the position x=1 y=1 is not necessarily located at the top left of the current image, but instead depends on the cumulative effect of the previous transformations. The reason for this is because affine transformations are usually performed around the center of the image, which is reflected in \"native space\". This is useful for combining transformations such as Rotate or ShearX with a crop around the center area.\n\nUsage\n\nCropNative(indices)\n\nCropNative(indices...)\n\nArguments\n\nindices : NTuple or Vararg of UnitRange that denote   the cropping range for each array dimension. This is very   similar to how the axes for view are specified.\n\nSee also\n\nCrop, CropSize, CropRatio, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# cropped at top left corner\naugment(img, Rotate(45) |> Crop(1:300, 1:400))\n\n# cropped around center of rotated image\naugment(img, Rotate(45) |> CropNative(1:300, 1:400))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/examples/mnist_elastic/#mnist_elastic","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"","category":"section"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"In this example we are going to use Augmentor on the famous MNIST database of handwritten digits [MNIST1998] to reproduce the elastic distortions discussed in [SIMARD2003].","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"It may be interesting to point out, that the way Augmentor implements distortions is a little different to how it is described by the authors of the paper. This is for a couple of reasons, most notably that we want the parameters for our deformations to be independent of the size of image it is applied on. As a consequence the parameter-numbers specified in the paper are not 1-to-1 transferable to Augmentor.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"If the effects are sensible for the dataset, then applying elastic distortions can be a really effective way to improve the generalization ability of the network. That said, our implementation of ElasticDistortion has a lot of possible parameters to choose from. To that end, we will introduce a simple strategy for interactively exploring the parameter space on our dataset of interest.","category":"page"},{"location":"examples/examples/mnist_elastic/#Loading-the-MNIST-Trainingset","page":"Elastic distortion to MNIST images","title":"Loading the MNIST Trainingset","text":"","category":"section"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"In order to access and visualize the MNIST images we employ the help of two additional Julia packages. In the interest of time and space we will not go into great detail about their functionality. Feel free to click on their respective names to find out more information about the utility they can provide.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"Images.jl will provide us with the necessary tools for working with image data in Julia.\nMLDatasets.jl has an MNIST submodule that offers a convenience interface to read the MNIST database.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"The function MNIST.traintensor returns the MNIST training images corresponding to the given indices as a multi-dimensional array. These images are stored in the native horizontal-major memory layout as a single floating point array, where all values are scaled to be between 0.0 and 1.0.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"using Images, MLDatasets\ntrain_tensor = MNIST.traintensor()\n\nsummary(train_tensor)","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"This horizontal-major format is the standard way of utilizing this dataset for training machine learning models. In this tutorial, however, we are more interested in working with the MNIST images as actual Julia images in vertical-major layout, and as black digits on white background.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"We can convert the \"tensor\" to a Colorant array using the provided function MNIST.convert2image. This way, Julia knows we are dealing with image data and can tell programming environments such as Juypter how to visualize it. If you are working in the terminal you may want to use the package ImageInTerminal.jl","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"train_images = MNIST.convert2image(train_tensor)\n\ntrain_images[:,:,1] # show first image","category":"page"},{"location":"examples/examples/mnist_elastic/#Visualizing-the-Effects","page":"Elastic distortion to MNIST images","title":"Visualizing the Effects","text":"","category":"section"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"Before applying an operation (or pipeline of operations) on some dataset to train a network, we strongly recommend investing some time in selecting a decent set of hyper parameters for the operation(s). A useful tool for tasks like this is the package Interact.jl. We will use this package to define a number of widgets for controlling the parameters to our operation.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"Note that while the code below only focuses on configuring the parameters of a single operation, specifically ElasticDistortion, it could also be adapted to tweak a whole pipeline. Take a look at the corresponding section in High-level Interface for more information on how to define and use a pipeline.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"These two package will provide us with the capabilities to perform interactive visualisations in a jupyter notebook using Augmentor, Interact, Reactive","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"The manipulate macro will turn the parameters of the loop into interactive widgets.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"@manipulate for\n        unpaused = true,\n        ticks = fpswhen(signal(unpaused), 5.),\n        image_index = 1:100,\n        grid_size = 3:20,\n        scale = .1:.1:.5,\n        sigma = 1:5,\n        iterations = 1:6,\n        free_border = true  op = ElasticDistortion(grid_size, grid_size, # equal width & height\n                           sigma = sigma,\n                           scale = scale,\n                           iter = iterations,\n                           border = free_border)\n    augment(train_images[:, :, image_index], op)\nend","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"Executing the code above in a Juypter notebook will result in the following interactive visualisation. You can now use the sliders to investigate the effects that different parameters have on the MNIST training images.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"tip: Tip\nYou should always use your training set to do this kind of visualisation (not the test test!). Otherwise you are likely to achieve overly optimistic (i.e. biased) results during training.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"(Image: interact)","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"Congratulations! With just a few simple lines of code, you created a simple interactive tool to visualize your image augmentation pipeline. Once you found a set of parameters that you think are appropriate for your dataset you can go ahead and train your model.","category":"page"},{"location":"examples/examples/mnist_elastic/#References","page":"Elastic distortion to MNIST images","title":"References","text":"","category":"section"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"[MNIST1998]: LeCun, Yan, Corinna Cortes, Christopher J.C. Burges. \"The MNIST database of handwritten digits\" Website. 1998.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"[SIMARD2003]: Simard, Patrice Y., David Steinkraus, and John C. Platt. \"Best practices for convolutional neural networks applied to visual document analysis.\" ICDAR. Vol. 3. 2003.","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"","category":"page"},{"location":"examples/examples/mnist_elastic/","page":"Elastic distortion to MNIST images","title":"Elastic distortion to MNIST images","text":"This page was generated using DemoCards.jl.","category":"page"},{"location":"operations/blur/gaussianblur/#GaussianBlur","page":"GaussianBlur","title":"GaussianBlur","text":"","category":"section"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"GaussianBlur can be used to blur the input image using a gaussian kernel with a specified kernel size and standard deviation.","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, GaussianBlur(3)),\n    augment(img_in, GaussianBlur(5, 2.5));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/blur/gaussianblur/#References","page":"GaussianBlur","title":"References","text":"","category":"section"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"GaussianBlur","category":"page"},{"location":"operations/blur/gaussianblur/#Augmentor.GaussianBlur","page":"GaussianBlur","title":"Augmentor.GaussianBlur","text":"GaussianBlur <: ImageOperation\n\nDescription\n\nBlurs an image using a Gaussian filter.\n\nUsage\n\nGaussianBlur(k, [σ])\n\nArguments\n\nk : Integer or AbstractVector of Integer that denote   the kernel size. It must be an odd positive number.\nσ : Optional. Real or AbstractVector of Real that denote the   standard deviation. It must be a positive number.   Defaults to 0.3 * ((k - 1) / 2 - 1) + 0.8.\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# use exactly k=3 and σ=1.0\naugment(img, GaussianBlur(3, 1.0))\n\n# pick k and σ randomly from the specified ranges\naugment(img, GaussianBlur(3:2:7, 1.0:0.1:2.0))\n\n\n\n\n\n","category":"type"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/color/colorjitter/#ColorJitter","page":"ColorJitter","title":"ColorJitter","text":"","category":"section"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"ColorJitter can be used to adjust the contrast and brightness of an input image.","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, ColorJitter(1.2, 0.3)),\n    augment(img_in, ColorJitter(0.75, -0.2));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/color/colorjitter/#References","page":"ColorJitter","title":"References","text":"","category":"section"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"ColorJitter","category":"page"},{"location":"operations/color/colorjitter/#Augmentor.ColorJitter","page":"ColorJitter","title":"Augmentor.ColorJitter","text":"ColorJitter <: ImageOperation\n\nDescription\n\nAdjusts the brightness and contrast of an image according to the formula α * image[i] + β * M, where M is either mean(image) or the maximum intensity value.\n\nUsage\n\nColorJitter()\nColorJitter(α, β; [usemax])\n\nArguments\n\nα : Real or AbstractVector of Real that denote the coefficient(s)   for contrast adjustment. Defaults to 0.8:0.1:1.2.\nβ : Real or AbstractVector of Real that denote the coefficient(s)   for brightness adjustment. Defaults to -0.2:0.1:0.2.\nusemax::Bool: Optional. If true, the brightness will be adjusted by   the maximum intensity value; otherwise, the image mean will be used.   Defaults to true.\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# use exactly 1.2 for contrast, and one of 0.5 and 0.8 for brightness\naugment(img, ColorJitter(1.2, [0.5, 0.8]))\n\n# pick the coefficients randomly from the specified ranges\naugment(img, ColorJitter(0.8:0.1:2.0, 0.5:0.1:1.1))\n\n\n\n\n\n","category":"type"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/distortions/elasticdistortion/#op_elastic","page":"ElasticDistortion","title":"ElasticDistortion","text":"","category":"section"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"Smoothed random distortion","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, ElasticDistortion(15,15,0.1)),\n    augment(img_in, ElasticDistortion(10,10,0.2,4,3,true));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/distortions/elasticdistortion/#Reference","page":"ElasticDistortion","title":"Reference","text":"","category":"section"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"ElasticDistortion","category":"page"},{"location":"operations/distortions/elasticdistortion/#Augmentor.ElasticDistortion","page":"ElasticDistortion","title":"Augmentor.ElasticDistortion","text":"ElasticDistortion <: Augmentor.ImageOperation\n\nDescription\n\nDistorts the given image using a randomly (uniform) generated vector field of the given grid size. This field will be stretched over the given image when applied, which in turn will morph the original image into a new image using a linear interpolation of both the image and the vector field.\n\nIn contrast to [RandomDistortion], the resulting vector field is also smoothed using a Gaussian filter with of parameter sigma. This will result in a less chaotic vector field and thus resemble a more natural distortion.\n\nUsage\n\nElasticDistortion(gridheight, gridwidth, scale, sigma, [iter=1], [border=false], [norm=true])\n\nElasticDistortion(gridheight, gridwidth, scale; [sigma=2], [iter=1], [border=false], [norm=true])\n\nElasticDistortion(gridheight, [gridwidth]; [scale=0.2], [sigma=2], [iter=1], [border=false], [norm=true])\n\nArguments\n\ngridheight : The grid height of the displacement vector   field. This effectively specifies the number of vertices   along the Y dimension used as landmarks, where all the   positions between the grid points are interpolated.\ngridwidth : The grid width of the displacement vector   field. This effectively specifies the number of vertices   along the Y dimension used as landmarks, where all the   positions between the grid points are interpolated.\nscale : Optional. The scaling factor applied to all   displacement vectors in the field. This effectively defines   the \"strength\" of the deformation. There is no theoretical   upper limit to this factor, but a value somewhere between   0.01 and 1.0 seem to be the most reasonable choices.   Default to 0.2.\nsigma : Optional. Sigma parameter of the Gaussian filter.   This parameter effectively controls the strength of the   smoothing. Defaults to 2.\niter : Optional. The number of times the smoothing   operation is applied to the displacement vector field. This   is especially useful if border = false because the border   will be reset to zero after each pass. Thus the displacement   is a little less aggressive towards the borders of the image   than it is towards its center. Defaults to   1.\nborder : Optional. Specifies if the borders should be   distorted as well. If false, the borders of the image will   be preserved. This effectively pins the outermost vertices on   their original position and the operation thus only distorts   the inner content of the image. Defaults to   false.\nnorm : Optional. If true, the displacement vectors of   the field will be normalized by the norm of the field. This   will have the effect that the scale factor should be more   or less independent of the grid size. Defaults to   true.\n\nSee also\n\naugment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# distort with pinned borders\naugment(img, ElasticDistortion(15, 15; scale = 0.1))\n\n# distort everything more smoothly.\naugment(img, ElasticDistortion(10, 10; sigma = 4, iter=3, border=true))\n\n\n\n\n\n","category":"type"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/misc/layout/#Colorant-conversion-and-channel-layout","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"","category":"section"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"Augmentor has warpped some commonly used basic operations so that you can use to build the augmentation pipeline. The internal column is what you'd probably do outside of Augmentor.","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"Category internal Augmentor\nConversion T.(img) ConvertEltype(T)\nInformation Layout ImageCore.channelview SplitChannels\nInformation Layout ImageCore.colorview CombineChannels\nInformation Layout Base.permutedims PermuteDims\nInformation Layout Base.reshape Reshape","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"It is not uncommon that machine learning frameworks require the data in a specific form and layout. For example many deep learning frameworks expect the colorchannel of the images to be encoded in the third dimension of a 4-dimensional array. Augmentor allows to convert from (and to) these different layouts using special operations that are mainly useful in the beginning or end of a augmentation pipeline.","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"using Augmentor\nusing ImageCore\n\n# 300×400 Matrix{RGB{N0f8}, 2} => 300×400×3 Array{Float32, 3}\nimg = testpattern(RGB, ratio=0.5)\nimg_in = augment(img, SplitChannels() |> PermuteDims(2, 3, 1) |> ConvertEltype(Float32))\n\n# 300×400×3 Array{Float32, 3} => 300×400 Matrix{RGB{N0f8}, 2}\nimg_out = augment(img_in, ConvertEltype(N0f8) |> PermuteDims(3, 1, 2) |> CombineChannels(RGB))\n\nimg_out == img","category":"page"},{"location":"operations/misc/layout/#References","page":"Colorant conversion and channel layout","title":"References","text":"","category":"section"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"ConvertEltype\nSplitChannels\nCombineChannels\nPermuteDims\nReshape","category":"page"},{"location":"operations/misc/layout/#Augmentor.ConvertEltype","page":"Colorant conversion and channel layout","title":"Augmentor.ConvertEltype","text":"ConvertEltype <: Augmentor.Operation\n\nDescription\n\nConvert the element type of the given array/image into the given eltype. This operation is especially useful for converting color images to grayscale (or the other way around). That said, the operation is not specific to color types and can also be used for numeric arrays (e.g. with separated channels).\n\nNote that this is an element-wise convert function. Thus it can not be used to combine or separate color channels. Use SplitChannels or CombineChannels for those purposes.\n\nUsage\n\nConvertEltype(eltype)\n\nArguments\n\neltype : The eltype of the resulting array/image.\n\nSee also\n\nCombineChannels, SplitChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(RGB, 10, 10) # three color channels\n10×10 Array{RGB{Float64},2}:\n[...]\n\njulia> augment(A, ConvertEltype(Gray{Float32})) # convert to grayscale\n10×10 Array{Gray{Float32},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.SplitChannels","page":"Colorant conversion and channel layout","title":"Augmentor.SplitChannels","text":"SplitChannels <: Augmentor.Operation\n\nDescription\n\nSplits out the color channels of the given image using the function ImageCore.channelview. This will effectively create a new array dimension for the colors in the front. In contrast to ImageCore.channelview it will also result in a new dimension for gray images.\n\nThis operation is mainly useful at the end of a pipeline in combination with PermuteDims in order to prepare the image for the training algorithm, which often requires the color channels to be separate.\n\nUsage\n\nSplitChannels()\n\nSee also\n\nPermuteDims, CombineChannels, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> augment(img, SplitChannels())\n4×300×400 Array{N0f8,3}:\n[...]\n\njulia> augment(img, SplitChannels() |> PermuteDims(3,2,1))\n400×300×4 Array{N0f8,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.CombineChannels","page":"Colorant conversion and channel layout","title":"Augmentor.CombineChannels","text":"CombineChannels <: Augmentor.Operation\n\nDescription\n\nCombines the first dimension of a given array into a colorant of type colortype using the function ImageCore.colorview. The main difference is that a separate color channel is also expected for Gray images.\n\nThe shape of the input image has to be appropriate for the given colortype, which also means that the separated color channel has to be the first dimension of the array. See PermuteDims if that is not the case.\n\nUsage\n\nCombineChannels(colortype)\n\nArguments\n\ncolortype : The color type of the resulting image. Must   be a subtype of ColorTypes.Colorant and match the color   channel of the given image.\n\nSee also\n\nSplitChannels, PermuteDims, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(3, 10, 10) # three color channels\n3×10×10 Array{Float64,3}:\n[...]\n\njulia> augment(A, CombineChannels(RGB))\n10×10 Array{RGB{Float64},2}:\n[...]\n\njulia> B = rand(1, 10, 10) # singleton color channel\n1×10×10 Array{Float64,3}:\n[...]\n\njulia> augment(B, CombineChannels(Gray))\n10×10 Array{Gray{Float64},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.PermuteDims","page":"Colorant conversion and channel layout","title":"Augmentor.PermuteDims","text":"PermuteDims <: Augmentor.Operation\n\nDescription\n\nPermute the dimensions of the given array with the predefined permutation perm. This operation is particularly useful if the order of the dimensions needs to be different than the default \"julian\" layout (described below).\n\nAugmentor expects the given images to be in vertical-major layout for which the colors are encoded in the element type itself. Many deep learning frameworks however require their input in a different order. For example it is not untypical that separate color channels are expected to be encoded in the third dimension.\n\nUsage\n\nPermuteDims(perm)\n\nPermuteDims(perm...)\n\nArguments\n\nperm : The concrete dimension permutation that should be   used. Has to be specified as a Vararg{Int} or as a NTuple   of Int. The length of perm has to match the number of   dimensions of the expected input image to that operation.\n\nSee also\n\nSplitChannels, CombineChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(10, 5, 3) # width=10, height=5, and 3 color channels\n10×5×3 Array{Float64,3}:\n[...]\n\njulia> img = augment(A, PermuteDims(3,2,1) |> CombineChannels(RGB))\n5×10 Array{RGB{Float64},2}:\n[...]\n\njulia> img2 = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> B = augment(img2, SplitChannels() |> PermuteDims(3,2,1))\n400×300×4 Array{N0f8,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.Reshape","page":"Colorant conversion and channel layout","title":"Augmentor.Reshape","text":"Reshape <: Augmentor.Operation\n\nDescription\n\nReinterpret the shape of the given array of numbers or colorants. This is useful for example to create singleton-dimensions that deep learning frameworks may need for colorless images, or for converting an image array to a feature vector (and vice versa).\n\nUsage\n\nReshape(dims)\n\nReshape(dims...)\n\nArguments\n\ndims : The new sizes for each dimension of the output   image. Has to be specified as a Vararg{Int} or as a   NTuple of Int.\n\nSee also\n\nCombineChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(10,10)\n10×10 Array{Float64,2}:\n[...]\n\njulia> augment(A, Reshape(10,10,1)) # add trailing singleton dimension\n10×10×1 Array{Float64,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/affine/resize/#Resize","page":"Resize","title":"Resize","text":"","category":"section"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"Set the static size of the image","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Resize(240, 320));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/resize/#References","page":"Resize","title":"References","text":"","category":"section"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"Resize","category":"page"},{"location":"operations/affine/resize/#Augmentor.Resize","page":"Resize","title":"Augmentor.Resize","text":"Resize <: Augmentor.ImageOperation\n\nDescription\n\nRescales the image to a fixed pre-specified pixel size.\n\nThis operation does not take any measures to preserve aspect ratio of the source image. Instead, the original image will simply be resized to the given dimensions. This is useful when one needs a set of images to all be of the exact same size.\n\nUsage\n\nResize(; height=64, width=64)\n\nResize(size)\n\nResize(size...)\n\nArguments\n\nsize : NTuple or Vararg of Int that denote the   output size in pixel for each dimension.\n\nSee also\n\nCropSize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\naugment(img, Resize(30, 40))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown, Augmentor\nMarkdown.parse_file(joinpath(pkgdir(Augmentor), \"LICENSE.md\"))","category":"page"},{"location":"background/#Background-and-Motivation","page":"Background and Motivation","title":"Background and Motivation","text":"","category":"section"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"In this section we will discuss the concept of image augmentation in general. In particular we will introduce some terminology and useful definitions.","category":"page"},{"location":"background/#What-is-Image-Augmentation?","page":"Background and Motivation","title":"What is Image Augmentation?","text":"","category":"section"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"The term data augmentation is commonly used to describe the process of repeatedly applying various transformations to some dataset, with the hope that the output (i.e. the newly generated observations) bias the model towards learning better features. Depending on the structure and semantics of the data, coming up with such transformations can be a challenge by itself.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Images are a special class of data that exhibit some interesting properties in respect to their structure. For example the dimensions of an image (i.e. the pixel) exhibit a spatial relationship to each other. As such, a lot of commonly used augmentation strategies for image data revolve around affine transformations, such as translations or rotations. Because images are so popular and special case of data, they deserve their own sub-category of data augmentation, which we will unsurprisingly refer to as image augmentation.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"The general idea is the following: if we want our model to generalize well, then we should design the learning process in such a way as to bias the model into learning such transformation-equivariant properties. One way to do this is via the design of the model itself, which for example was idea behind convolutional neural networks. An orthogonal approach to bias the model to learn about this equivariance - and the focus of this package - is by using label-preserving transformations.","category":"page"},{"location":"background/#labelpreserving","page":"Background and Motivation","title":"Label-preserving Transformations","text":"","category":"section"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Before attempting to train a model using some augmentation pipeline, it's a good idea to invest some time in deciding on an appropriate set of transformations to choose from. Some of these transformations also have parameters to tune, and we should also make sure that we settle on a decent set of values for those.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"What constitutes as \"decent\" depends on the dataset. In general we want the augmented images to be fairly dissimilar to the originals. However, we need to be careful that the augmented images still visually represent the same concept (and thus label). If a pipeline only produces output images that have this property we call this pipeline label-preserving.","category":"page"},{"location":"background/#mnist","page":"Background and Motivation","title":"Example: MNIST Handwritten Digits","text":"","category":"section"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Consider the following example from the MNIST database of handwritten digits [MNIST1998]. Our input image clearly represents its associated label \"6\". If we were to use the transformation Rotate180 in our augmentation pipeline for this type of images, we could end up with the situation depicted by the image on the right side.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"using Augmentor, MLDatasets\ninput_img  = MNIST.convert2image(MNIST.traintensor(19))\noutput_img = augment(input_img, Rotate180())\nusing Images, FileIO; # hide\nupsize(A) = repeat(A, inner=(4,4)); # hide\nsave(joinpath(\"assets\",\"bg_mnist_in.png\"), upsize(input_img)); # hide\nsave(joinpath(\"assets\",\"bg_mnist_out.png\"), upsize(output_img)); # hide\nnothing # hide","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Input (input_img) Output (output_img)\n(Image: input) (Image: output)","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"To a human, this newly transformed image clearly represents the label \"9\", and not \"6\" like the original image did. In image augmentation, however, the assumption is that the output of the pipeline has the same label as the input. That means that in this example we would tell our model that the correct answer for the image on the right side is \"6\", which is clearly undesirable for obvious reasons.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Thus, for the MNIST dataset, the transformation Rotate180 is not label-preserving and should not be used for augmentation.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"[MNIST1998]: LeCun, Yan, Corinna Cortes, Christopher J.C. Burges. \"The MNIST database of handwritten digits\" Website. 1998.","category":"page"},{"location":"background/#Example:-ISIC-Skin-Lesions","page":"Background and Motivation","title":"Example: ISIC Skin Lesions","text":"","category":"section"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"On the other hand, the exact same transformation could very well be label-preserving for other types of images. Let us take a look at a different set of image data; this time from the medical domain.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"The International Skin Imaging Collaboration [ISIC] hosts a large collection of publicly available and labeled skin lesion images. A subset of that data was used in 2016's ISBI challenge [ISBI2016] where a subtask was lesion classification.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Let's consider the following input image on the left side. It shows a photo of a skin lesion that was taken from above. By applying the Rotate180 operation to the input image, we end up with a transformed version shown on the right side.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"using Augmentor, ISICArchive\ninput_img  = get(ImageThumbnailRequest(id = \"5592ac599fc3c13155a57a85\"))\noutput_img = augment(input_img, Rotate180())\nusing FileIO; # hide\nsave(joinpath(\"assets\",\"bg_isic_in.png\"), input_img); # hide\nsave(joinpath(\"assets\",\"bg_isic_out.png\"), output_img); # hide\nnothing # hide","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"Input (input_img) Output (output_img)\n(Image: input) (Image: output)","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"After looking at both images, one could argue that the orientation of the camera is somewhat arbitrary as long as it points to the lesion at an approximately orthogonal angle. Thus, for the ISIC dataset, the transformation Rotate180 could be considered as label-preserving and very well be tried for augmentation. Of course this does not guarantee that it will improve training time or model accuracy, but the point is that it is unlikely to hurt.","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"[ISIC]: https://isic-archive.com/","category":"page"},{"location":"background/","page":"Background and Motivation","title":"Background and Motivation","text":"[ISBI2016]: Gutman, David; Codella, Noel C. F.; Celebi, Emre; Helba, Brian; Marchetti, Michael; Mishra, Nabin; Halpern, Allan. \"Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC)\". eprint arXiv:1605.01397. 2016.","category":"page"},{"location":"operations/misc/utilities/#Composition-utilities","page":"Composition utilities","title":"Composition utilities","text":"","category":"section"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"Aside from \"true\" operations that specify some kind of transformation, there are also a couple of special utility operations used for functionality such as stochastic branching.","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"using Augmentor\nusing Random\nRandom.seed!(1337)\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, Either(0.5=>NoOp(), 0.25=>FlipX(), 0.25=>FlipY()))\nnothing #hide","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"(Image: )","category":"page"},{"location":"operations/misc/utilities/#References","page":"Composition utilities","title":"References","text":"","category":"section"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"NoOp\nEither\nCacheImage","category":"page"},{"location":"operations/misc/utilities/#Augmentor.NoOp","page":"Composition utilities","title":"Augmentor.NoOp","text":"NoOp <: Augmentor.AffineOperation\n\nIdentity transformation that does not do anything with the given image, but instead passes it along unchanged (without copying).\n\nUsually used in combination with Either to denote a \"branch\" that does not perform any computation.\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/#Augmentor.Either","page":"Composition utilities","title":"Augmentor.Either","text":"Either <: Augmentor.ImageOperation\n\nDescription\n\nChooses between the given operations at random when applied. This is particularly useful if one for example wants to first either rotate the image 90 degree clockwise or anticlockwise (but never both), and then apply some other operation(s) afterwards.\n\nWhen compiling a pipeline, Either will analyze the provided operations in order to identify the preferred formalism to use when applied. The chosen formalism is chosen such that it is supported by all given operations. This way the output of applying Either will be inferable and the whole pipeline will remain type-stable (even though randomness is involved).\n\nBy default each specified image operation has the same probability of occurrence. This default behaviour can be overwritten by specifying the chance manually.\n\nUsage\n\nEither(operations, [chances])\n\nEither(operations...; [chances])\n\nEither(pairs...)\n\n*(operations...)\n\n*(pairs...)\n\nArguments\n\noperations : NTuple or Vararg of Augmentor.ImageOperation   that denote the possible choices to sample from when applied.\nchances : Optional. Denotes the relative chances for an   operation to be sampled. Has to contain the same number of   elements as operations. Either an NTuple of numbers if   specified as positional argument, or alternatively a   AbstractVector of numbers if specified as a keyword   argument. If omitted every operation will have equal   probability of occurring.\npairs : Vararg of Pair{<:Real,<:Augmentor.ImageOperation}.   A compact way to specify an operation and its chance of   occurring together.\n\nSee also\n\nNoOp, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# all three operations have equal chance of occuring\naugment(img, Either(FlipX(), FlipY(), NoOp()))\naugment(img, FlipX() * FlipY() * NoOp())\n\n# NoOp is twice as likely as either FlipX or FlipY\naugment(img, Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()))\naugment(img, Either(FlipX(), FlipY(), NoOp(), chances=[1,1,2]))\naugment(img, Either((FlipX(), FlipY(), NoOp()), (1,1,2)))\naugment(img, (1=>FlipX()) * (1=>FlipY()) * (2=>NoOp()))\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/#Augmentor.CacheImage","page":"Composition utilities","title":"Augmentor.CacheImage","text":"CacheImage <: Augmentor.ImageOperation\n\nDescription\n\nWrite the current state of the image into the working memory. Optionally a user has the option to specify a preallocated buffer to write the image into. Note that if a buffer is provided, then it has to be of the correct size and eltype.\n\nEven without a preallocated buffer it can be beneficial in some situations to cache the image. An example for such a scenario is when chaining a number of affine transformations after an elastic distortion, because performing that lazily requires nested interpolation.\n\nUsage\n\nCacheImage()\n\nCacheImage(buffer)\n\nArguments\n\nbuffer : Optional. A preallocated AbstractArray of the   appropriate size and eltype.\n\nSee also\n\naugment\n\nExamples\n\nusing Augmentor\n\n# make pipeline that forces caching after elastic distortion\npl = ElasticDistortion(3,3) |> CacheImage() |> Rotate(-10:10) |> ShearX(-5:5)\n\n# cache output of elastic distortion into the allocated\n# 20x20 Matrix{Float64}. Note that for this case this assumes that\n# the input image is also a 20x20 Matrix{Float64}\npl = ElasticDistortion(3,3) |> CacheImage(zeros(20,20)) |> Rotate(-10:10)\n\n# convenience syntax with the same effect as above.\npl = ElasticDistortion(3,3) |> zeros(20,20) |> Rotate(-10:10)\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"","page":"Home","title":"Home","text":"A fast library for increasing the number of training images by applying various transformations.","category":"page"},{"location":"#Augmentor.jl's-documentation","page":"Home","title":"Augmentor.jl's documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Augmentor is a real-time image augmentation library designed to render the process of artificial dataset enlargement more convenient, less error prone, and easier to reproduce. It offers the user the ability to build a stochastic image-processing pipeline (or simply augmentation pipeline) using image operations as building blocks. In other words, an augmentation pipeline is little more but a sequence of operations for which the parameters can (but need not) be random variables, as the following code snippet demonstrates.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Augmentor\npl = ElasticDistortion(6, scale=0.3, border=true) |>\n     Rotate([10, -5, -3, 0, 3, 5, 10]) |>\n     ShearX(-10:10) * ShearY(-10:10) |>\n     CropSize(28, 28) |>\n     Zoom(0.9:0.1:1.2)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Such a pipeline can then be used for sampling. Here we use the first few examples of the MNIST database.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Augmentor, ImageCore, ImageMagick\nusing MLDatasets\nusing Random\n\n# copied from operations/assets/gif.jl\nfunction make_gif(img, pl, num_sample; random_seed=1337, kwargs...)\n    fillvalue = oneunit(eltype(img[1]))\n\n    init_frame = mosaicview(img; kwargs...)\n    frames = map(1:num_sample-1) do _\n        mosaicview(map(x->augment(x, pl), img)...; kwargs...)\n    end\n\n    frames = sym_paddedviews(fillvalue, init_frame, frames...)\n    cat(frames..., dims=3)\nend\n\npl = ElasticDistortion(6, scale=0.3, border=true) |>\n     Rotate([10, -5, -3, 0, 3, 5, 10]) |>\n     ShearX(-10:10) * ShearY(-10:10) |>\n     CropSize(28, 28) |>\n     Zoom(0.9:0.1:1.2)\n\nn_samples, n_frames = 24, 10\nimgs = [MNIST.convert2image(MNIST.traintensor(i)) for i in 1:n_samples]\npreview = make_gif(imgs, pl, n_frames; nrow=1)\n\nImageMagick.save(\"mnist_preview.gif\", RGB(1, 1, 1) .- preview; fps=3)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: mnist_preview)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Julia version of Augmentor is engineered specifically for high performance applications. It makes use of multiple heuristics to generate efficient tailor-made code for the concrete user-specified augmentation pipeline. In particular Augmentor tries to avoid the need for any intermediate images, but instead aims to compute the output image directly from the input in one single pass.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the Python version of Augmentor, you can find it here","category":"page"},{"location":"#Where-to-begin?","page":"Home","title":"Where to begin?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If this is the first time you consider using Augmentor.jl for your machine learning related experiments or packages, make sure to check out the \"Getting Started\" section. There we list the installation instructions and some simple hello world examples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"gettingstarted.md\"]\nDepth = 2","category":"page"},{"location":"#Introduction-and-Motivation","page":"Home","title":"Introduction and Motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you are new to image augmentation in general, or are simply interested in some background information, feel free to take a look at the following sections. There we discuss the concepts involved and outline the most important terms and definitions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"background.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"In case you have not worked with image data in Julia before, feel free to browse the following documents for a crash course on how image data is represented in the Julia language, as well as how to visualize it. For more information on image processing in Julia, take a look at the documentation for the vast JuliaImages ecosystem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"images.md\"]\nDepth = 2","category":"page"},{"location":"#User's-Guide","page":"Home","title":"User's Guide","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As the name suggests, Augmentor was designed with image augmentation for machine learning in mind. That said, the way the library is implemented allows it to also be used for efficient image processing outside the machine learning domain.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The following section describes the high-level user interface in detail. In particular it focuses on how a (stochastic) image-processing pipeline can be defined and then be applied to an image (or a set of images). It also discusses how batch processing of multiple images can be performed in parallel using multi-threading.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"interface.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"We mentioned before that an augmentation pipeline is just a sequence of image operations. Augmentor ships with a number of predefined operations, which should be sufficient to describe the most commonly utilized augmentation strategies. Each operation is represented as its own unique type. The following section provides a complete list of all the exported operations and their documentation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"operations.md\"]\nDepth = 2","category":"page"},{"location":"#Tutorials","page":"Home","title":"Tutorials","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Just like an image can say more than a thousand words, a simple hands-on tutorial showing actual code can say more than many pages of formal documentation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first step of devising a successful augmentation strategy is to identify an appropriate set of operations and parameters. What that means can vary widely, because the utility of each operation depends on the dataset at hand (see label-preserving transformations for an example). To that end, we will spend the first tutorial discussing a simple but useful approach to interactively explore and visualize the space of possible parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [joinpath(\"generated\", \"mnist_elastic.md\")]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the next tutorials we will take a close look at how we can actually use Augmentor in combination with popular deep learning frameworks. The first framework we will discuss will be Knet. In particular we will focus on adapting an already existing example to make use of a (quite complicated) augmentation pipeline. Furthermore, this tutorial will also serve to showcase the various ways that augmentation can influence the performance of your network.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [joinpath(\"generated\", \"mnist_knet.md\")]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Pages = [joinpath(\"generated\", fname) for fname in readdir(\"generated\") if splitext(fname)[2] == \".md\"]\n# Depth = 2","category":"page"},{"location":"#Citing-Augmentor","page":"Home","title":"Citing Augmentor","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use Augmentor for academic research and wish to cite it, please use the following paper.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Marcus D. Bloice, Christof Stocker, and Andreas Holzinger, Augmentor: An Image Augmentation Library for Machine Learning, arXiv preprint arXiv:1708.04680, https://arxiv.org/abs/1708.04680, 2017.","category":"page"},{"location":"#Indices","page":"Home","title":"Indices","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"indices.md\"]","category":"page"},{"location":"operations/affine/rotate/#Rotate","page":"Rotate","title":"Rotate","text":"","category":"section"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"The type Rotate defines a generic anticlockwise rotation operation around the center of the image. It is also possible to pass some abstract vector to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\nRandom.seed!(0)\n\nimg_in = testpattern(RGB, ratio=0.5)\nmosaicview(\n    img_in,\n\n    # deterministic rotation\n    augment(img_in, Rotate(45)),\n\n    # random rotation\n    augment(img_in, Rotate(-45:45));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Note that the output image size will be changed after rotation, CropNative can be particalually useful to preserve the image size.","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"mosaicview(\n    augment(img_in, Rotate(45)),\n    augment(img_in, Rotate(45) |> CropNative(axes(img_in)));\n    nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Rotation by some special degree (e.g.,90, 180 and 270) can be handled more efficiently without interpolation. Compared to Rotate(90), it is recommended to use Rotate90 when possible. Rotate180 and Rotate270 are available, too.","category":"page"},{"location":"operations/affine/rotate/#References","page":"Rotate","title":"References","text":"","category":"section"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Rotate\nRotate90\nRotate180\nRotate270","category":"page"},{"location":"operations/affine/rotate/#Augmentor.Rotate","page":"Rotate","title":"Augmentor.Rotate","text":"Rotate <: Augmentor.AffineOperation\n\nDescription\n\nRotate the image upwards for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIn contrast to the special case rotations (e.g. Rotate90, the type Rotate can describe any arbitrary number of degrees. It will always perform the rotation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nRotate(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the rotation angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nRotate90, Rotate180, Rotate270, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# rotate exactly 45 degree\naugment(img, Rotate(45))\n\n# rotate between 10 and 20 degree upwards\naugment(img, Rotate(10:20))\n\n# rotate one of the five specified degrees\naugment(img, Rotate([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate90","page":"Rotate","title":"Augmentor.Rotate90","text":"Rotate90 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image upwards 90 degrees. This is a special case rotation because it can be performed very efficiently by simply rearranging the existing pixels. However, it is generally not the case that the output image will have the same size as the input image, which is something to be aware of.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate90(), 1-p=>NoOp()), where p denotes the probability of applying Rotate90 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate90()\n\nRotate90(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate180, Rotate270, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate90())\n2×2 Matrix{Int64}:\n 150   1\n 200  50\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate180","page":"Rotate","title":"Augmentor.Rotate180","text":"Rotate180 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image 180 degrees. This is a special case rotation because it can be performed very efficiently by simply rearranging the existing pixels. Furthermore, the output image will have the same dimensions as the input image.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate180(), 1-p=>NoOp()), where p denotes the probability of applying Rotate180 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate180()\n\nRotate180(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate90, Rotate270, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate180())\n2×2 Matrix{Int64}:\n   1   50\n 150  200\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate270","page":"Rotate","title":"Augmentor.Rotate270","text":"Rotate270 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image upwards 270 degrees, which can also be described as rotating the image downwards 90 degrees. This is a special case rotation, because it can be performed very efficiently by simply rearranging the existing pixels. However, it is generally not the case that the output image will have the same size as the input image, which is something to be aware of.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate270(), 1-p=>NoOp()), where p denotes the probability of applying Rotate270 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate270()\n\nRotate270(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate90, Rotate180, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate270())\n2×2 Matrix{Int64}:\n 50  200\n  1  150\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/cropratio/#CropRatio","page":"CropRatio","title":"CropRatio","text":"","category":"section"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"Crop centered window to fit given aspect ratio","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, CropRatio()) # crop out a square window\n\nmosaicview(img_in, img_out; nrow=1)","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"RCropRatio is a random version that randomly choose a crop center – not necessarily the center of the input image.","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"augment(img_in, RCropRatio())\nnothing #hide","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"(Image: )","category":"page"},{"location":"operations/size/cropratio/#Reference","page":"CropRatio","title":"Reference","text":"","category":"section"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"CropRatio\nRCropRatio","category":"page"},{"location":"operations/size/cropratio/#Augmentor.CropRatio","page":"CropRatio","title":"Augmentor.CropRatio","text":"CropRatio <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the biggest area around the center of the given image such that the output image satisfies the specified aspect ratio (i.e. width divided by height).\n\nFor example the operation CropRatio(1) would denote a crop for the biggest square around the center of the image.\n\nFor randomly placed crops take a look at RCropRatio.\n\nUsage\n\nCropRatio(ratio)\n\nCropRatio(; ratio = 1)\n\nArguments\n\nratio::Number : Optional. A number denoting the aspect   ratio. For example specifying ratio=16/9 would denote a 16:9   aspect ratio. Defaults to 1, which describes a square crop.\n\nSee also\n\nRCropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop biggest square around the image center\naugment(img, CropRatio(1))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropratio/#Augmentor.RCropRatio","page":"CropRatio","title":"Augmentor.RCropRatio","text":"RCropRatio <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the biggest possible area at some random position of the given image, such that the output image satisfies the specified aspect ratio (i.e. width divided by height).\n\nFor example the operation RCropRatio(1) would denote a crop for the biggest possible square. If there is more than one such square, then one will be selected at random.\n\nUsage\n\nRCropRatio(ratio)\n\nRCropRatio(; ratio = 1)\n\nArguments\n\nratio::Number : Optional. A number denoting the aspect   ratio. For example specifying ratio=16/9 would denote a 16:9   aspect ratio. Defaults to 1, which describes a square crop.\n\nSee also\n\nRCropSize, CropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop a randomly placed square of maxmimum size\naugment(img, RCropRatio(1))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"}]
}
