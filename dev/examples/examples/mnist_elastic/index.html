<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Elastic distortion to MNIST images · Augmentor.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../../democards/gridtheme.css" rel="stylesheet" type="text/css"/><link href="../../../democards/listtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="Augmentor.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Augmentor.jl</span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../gettingstarted/">Getting Started</a></li><li><span class="tocitem">Introduction and Motivation</span><ul><li><a class="tocitem" href="../../../background/">Background and Motivation</a></li><li><a class="tocitem" href="../../../images/">Working with Images in Julia</a></li></ul></li><li><span class="tocitem">User&#39;s Guide</span><ul><li><a class="tocitem" href="../../../interface/">High-level Interface</a></li><li><a class="tocitem" href="../../../operations/">Supported Operations</a></li></ul></li><li><a class="tocitem" href="../../">Tutorials</a></li><li><a class="tocitem" href="../../../LICENSE/">LICENSE</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Elastic distortion to MNIST images</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Elastic distortion to MNIST images</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Evizero/Augmentor.jl/blob/master/docs/examples/examples/mnist_elastic.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="mnist_elastic"><a class="docs-heading-anchor" href="#mnist_elastic">Elastic distortion to MNIST images</a><a id="mnist_elastic-1"></a><a class="docs-heading-anchor-permalink" href="#mnist_elastic" title="Permalink"></a></h1><p>In this example we are going to use Augmentor on the famous <strong>MNIST database of handwritten digits</strong> <sup class="footnote-reference"><a id="citeref-MNIST1998" href="#footnote-MNIST1998">[MNIST1998]</a></sup> to reproduce the elastic distortions discussed in <sup class="footnote-reference"><a id="citeref-SIMARD2003" href="#footnote-SIMARD2003">[SIMARD2003]</a></sup>.</p><p>It may be interesting to point out, that the way Augmentor implements distortions is a little different to how it is described by the authors of the paper. This is for a couple of reasons, most notably that we want the parameters for our deformations to be independent of the size of image it is applied on. As a consequence the parameter-numbers specified in the paper are not 1-to-1 transferable to Augmentor.</p><p>If the effects are sensible for the dataset, then applying elastic distortions can be a really effective way to improve the generalization ability of the network. That said, our implementation of <a href="../../../operations/distortions/elasticdistortion/#Augmentor.ElasticDistortion"><code>ElasticDistortion</code></a> has a lot of possible parameters to choose from. To that end, we will introduce a simple strategy for interactively exploring the parameter space on our dataset of interest.</p><h2 id="Loading-the-MNIST-Trainingset"><a class="docs-heading-anchor" href="#Loading-the-MNIST-Trainingset">Loading the MNIST Trainingset</a><a id="Loading-the-MNIST-Trainingset-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-the-MNIST-Trainingset" title="Permalink"></a></h2><p>In order to access and visualize the MNIST images we employ the help of two additional Julia packages. In the interest of time and space we will not go into great detail about their functionality. Feel free to click on their respective names to find out more information about the utility they can provide.</p><ul><li><p><a href="https://github.com/JuliaImages/Images.jl">Images.jl</a> will provide us with the necessary tools for working with image data in Julia.</p></li><li><p><a href="https://github.com/JuliaML/MLDatasets.jl">MLDatasets.jl</a> has an MNIST submodule that offers a convenience interface to read the MNIST database.</p></li></ul><p>The function <code>MNIST.traintensor</code> returns the MNIST training images corresponding to the given indices as a multi-dimensional array. These images are stored in the native horizontal-major memory layout as a single floating point array, where all values are scaled to be between 0.0 and 1.0.</p><pre><code class="language-julia">using Images, MLDatasets
train_tensor = MNIST.traintensor()

summary(train_tensor)</code></pre><pre class="documenter-example-output">&quot;28×28×60000 reinterpret(FixedPointNumbers.N0f8, ::Array{UInt8, 3})&quot;</pre><p>This horizontal-major format is the standard way of utilizing this dataset for training machine learning models. In this tutorial, however, we are more interested in working with the MNIST images as actual Julia images in vertical-major layout, and as black digits on white background.</p><p>We can convert the &quot;tensor&quot; to a <code>Colorant</code> array using the provided function <code>MNIST.convert2image</code>. This way, Julia knows we are dealing with image data and can tell programming environments such as Juypter how to visualize it. If you are working in the terminal you may want to use the package <a href="https://github.com/JuliaImages/ImageInTerminal.jl">ImageInTerminal.jl</a></p><pre><code class="language-julia">train_images = MNIST.convert2image(train_tensor)

train_images[:,:,1] # show first image</code></pre><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJggg==" /><h2 id="Visualizing-the-Effects"><a class="docs-heading-anchor" href="#Visualizing-the-Effects">Visualizing the Effects</a><a id="Visualizing-the-Effects-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-Effects" title="Permalink"></a></h2><p>Before applying an operation (or pipeline of operations) on some dataset to train a network, we strongly recommend investing some time in selecting a decent set of hyper parameters for the operation(s). A useful tool for tasks like this is the package <a href="https://github.com/JuliaGizmos/Interact.jl">Interact.jl</a>. We will use this package to define a number of widgets for controlling the parameters to our operation.</p><p>Note that while the code below only focuses on configuring the parameters of a single operation, specifically <a href="../../../operations/distortions/elasticdistortion/#Augmentor.ElasticDistortion"><code>ElasticDistortion</code></a>, it could also be adapted to tweak a whole pipeline. Take a look at the corresponding section in <a href="../../../interface/#pipeline">High-level Interface</a> for more information on how to define and use a pipeline.</p><p>These two package will provide us with the capabilities to perform interactive visualisations in a jupyter notebook using Augmentor, Interact, Reactive</p><p>The manipulate macro will turn the parameters of the loop into interactive widgets.</p><pre><code class="language-julia">@manipulate for
        unpaused = true,
        ticks = fpswhen(signal(unpaused), 5.),
        image_index = 1:100,
        grid_size = 3:20,
        scale = .1:.1:.5,
        sigma = 1:5,
        iterations = 1:6,
        free_border = true  op = ElasticDistortion(grid_size, grid_size, # equal width &amp; height
                           sigma = sigma,
                           scale = scale,
                           iter = iterations,
                           border = free_border)
    augment(train_images[:, :, image_index], op)
end</code></pre><p>Executing the code above in a Juypter notebook will result in the following interactive visualisation. You can now use the sliders to investigate the effects that different parameters have on the MNIST training images.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>You should always use your <strong>training</strong> set to do this kind of visualisation (not the test test!). Otherwise you are likely to achieve overly optimistic (i.e. biased) results during training.</p></div></div><p><img src="https://user-images.githubusercontent.com/10854026/30867456-4afe0800-a2dc-11e7-90eb-800b6ea025d0.gif" alt="interact"/></p><p>Congratulations! With just a few simple lines of code, you created a simple interactive tool to visualize your image augmentation pipeline. Once you found a set of parameters that you think are appropriate for your dataset you can go ahead and train your model.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><hr/><p><em>This page was generated using <a href="https://github.com/johnnychen94/DemoCards.jl">DemoCards.jl</a>.</em></p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-MNIST1998"><a class="tag is-link" href="#citeref-MNIST1998">MNIST1998</a>LeCun, Yan, Corinna Cortes, Christopher J.C. Burges. <a href="http://yann.lecun.com/exdb/mnist/">&quot;The MNIST database of handwritten digits&quot;</a> Website. 1998.</li><li class="footnote" id="footnote-SIMARD2003"><a class="tag is-link" href="#citeref-SIMARD2003">SIMARD2003</a>Simard, Patrice Y., David Steinkraus, and John C. Platt. <a href="https://www.microsoft.com/en-us/research/publication/best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis/">&quot;Best practices for convolutional neural networks applied to visual document analysis.&quot;</a> ICDAR. Vol. 3. 2003.</li></ul></section></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 12 July 2021 18:57">Monday 12 July 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
