var documenterSearchIndex = {"docs":
[{"location":"operations/affine/flip/#Flip","page":"Flip","title":"Flip","text":"","category":"section"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"FlipX/FlipY can be used to flip the input image horizontally/vertically.","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, FlipX()),\n    augment(img_in, FlipY());\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"To perform a random flip, you can also pass the probablity to the constructor. For example, FlipX(0.5) flips the image with half chance.","category":"page"},{"location":"operations/affine/flip/#References","page":"Flip","title":"References","text":"","category":"section"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"FlipX\nFlipY","category":"page"},{"location":"operations/affine/flip/#Augmentor.FlipX","page":"Flip","title":"Augmentor.FlipX","text":"FlipX <: Augmentor.AffineOperation\n\nDescription\n\nReverses the x-order of each pixel row. Another way of describing it would be that it mirrors the image on the y-axis, or that it mirrors the image horizontally.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>FlipX(), 1-p=>NoOp()), where p denotes the probability of applying FlipX and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nFlipX()\n\nFlipX(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nFlipY, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, FlipX())\n2×2 Matrix{Int64}:\n 150  200\n   1   50\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/flip/#Augmentor.FlipY","page":"Flip","title":"Augmentor.FlipY","text":"FlipY <: Augmentor.AffineOperation\n\nDescription\n\nReverses the y-order of each pixel column. Another way of describing it would be that it mirrors the image on the x-axis, or that it mirrors the image vertically.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>FlipY(), 1-p=>NoOp()), where p denotes the probability of applying FlipY and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nFlipY()\n\nFlipY(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nFlipX, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, FlipY())\n2×2 Matrix{Int64}:\n  50    1\n 200  150\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"","category":"page"},{"location":"operations/affine/flip/","page":"Flip","title":"Flip","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/affine/scale/#Scale","page":"Scale","title":"Scale","text":"","category":"section"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Relatively resizing image","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"In the case that only a single scale factor is specified, the operation will assume that the intention is to scale all dimensions uniformly by that factor.","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"img_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Scale(0.8)),\n    augment(img_in, Scale(0.8, 1));\n\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"It is also possible to pass some abstract vector(s) to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Random.seed!(1337)\nimg_out = [augment(img_in, Scale(0.9:0.05:1.2)) for _ in 1:4]\nmosaicview(img_out...; fillvalue=colorant\"white\", nrow=2)","category":"page"},{"location":"operations/affine/scale/#References","page":"Scale","title":"References","text":"","category":"section"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"Scale","category":"page"},{"location":"operations/affine/scale/#Augmentor.Scale","page":"Scale","title":"Augmentor.Scale","text":"Scale <: Augmentor.AffineOperation\n\nDescription\n\nMultiplies the image height and image width by the specified factors. This means that the size of the output image depends on the size of the input image.\n\nThe provided factors can either be numbers or vectors of numbers.\n\nIf numbers are provided, then the operation is deterministic and will always scale the input image with the same factors.\nIn the case vectors are provided, then each time the operation is applied a valid index is sampled and the elements corresponding to that index are used as scaling factors.\n\nThe scaling is performed relative to the image center, which can be useful when following the operation with CropNative.\n\nUsage\n\nScale(factors)\n\nScale(factors...)\n\nArguments\n\nfactors : NTuple or Vararg of Real or   AbstractVector that denote the scale factor(s) for each   array dimension. If only one variable is specified it is   assumed that height and width should be scaled by the same   factor(s).\n\nSee also\n\nZoom, Resize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# half the image size\naugment(img, Scale(0.5))\n\n# uniformly scale by a random factor from 1.2, 1.3, or 1.4\naugment(img, Scale([1.2, 1.3, 1.4]))\n\n# scale by either 0.5x0.7 or by 0.6x0.8\naugment(img, Scale([0.5, 0.6], [0.7, 0.8]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"","category":"page"},{"location":"operations/affine/scale/","page":"Scale","title":"Scale","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/misc/higherorder/#Higher-order-functions","page":"Higher-order functions","title":"Higher-order functions","text":"","category":"section"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"These operations are useful to perform an operation that is not explicitly defined in Augmentor.","category":"page"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"using Augmentor\nusing Random\nusing Statistics: mean\n\nRandom.seed!(1337)\n\nDecreaseContrast = MapFun(pixel -> pixel / 2)\nIncreaseBrightness = AggregateThenMapFun(img -> mean(img),\n                                         (pixel, M) -> pixel + M / 5)\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, DecreaseContrast |> IncreaseBrightness)","category":"page"},{"location":"operations/misc/higherorder/#References","page":"Higher-order functions","title":"References","text":"","category":"section"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"MapFun\nAggregateThenMapFun","category":"page"},{"location":"operations/misc/higherorder/#Augmentor.MapFun","page":"Higher-order functions","title":"Augmentor.MapFun","text":"MapFun <: Augmentor.Operation\n\nDescription\n\nMaps the given function over all individual array elements.\n\nThis means that the given function is called with an individual elements and is expected to return a transformed element that should take the original's place. This further implies that the function is expected to be unary. It is encouraged that the function should be consistent with its return type and type-stable.\n\nUsage\n\nMapFun(fun)\n\nArguments\n\nfun : The unary function that should be mapped over all   individual array elements.\n\nSee also\n\nAggregateThenMapFun, ConvertEltype, augment\n\nExamples\n\nusing Augmentor, ColorTypes\nimg = testpattern()\n\n# subtract the constant RGBA value from each pixel\naugment(img, MapFun(px -> px - RGBA(0.5, 0.3, 0.7, 0.0)))\n\n# separate channels to scale each numeric element by a constant value\npl = SplitChannels() |> MapFun(el -> el * 0.5) |> CombineChannels(RGBA)\naugment(img, pl)\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/higherorder/#Augmentor.AggregateThenMapFun","page":"Higher-order functions","title":"Augmentor.AggregateThenMapFun","text":"AggregateThenMapFun <: Augmentor.Operation\n\nDescription\n\nCompute some aggregated value of the current image using the given function aggfun, and map that value over the current image using the given function mapfun.\n\nThis is particularly useful for achieving effects such as per-image normalization.\n\nUsage\n\nAggregateThenMapFun(aggfun, mapfun)\n\nArguments\n\naggfun : A function that takes the whole current image as   input and which result will also be passed to mapfun. It   should have a signature of img -> agg, where img will the   the current image. What type and value agg should be is up   to the user.\nmapfun : The binary function that should be mapped over   all individual array elements. It should have a signature of   (px, agg) -> new_px where px is a single element of the   current image, and agg is the output of aggfun.\n\nSee also\n\nMapFun, ConvertEltype, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# subtract the average RGB value of the current image\naugment(img, AggregateThenMapFun(img -> mean(img), (px, agg) -> px - agg))\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"","category":"page"},{"location":"operations/misc/higherorder/","page":"Higher-order functions","title":"Higher-order functions","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/cropsize/#CropSize","page":"CropSize","title":"CropSize","text":"","category":"section"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"Crop centered window to given size","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, CropSize(70, 70)) # crop out a square window\n\nmosaicview(img_in, img_out; nrow=1, npad=10)","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"RCropSize is a random version that randomly choose a crop center – not necessarily the center of the input image.","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"augment(img_in, CropSize(70, 70))\nnothing #hide","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"(Image: )","category":"page"},{"location":"operations/size/cropsize/#Reference","page":"CropSize","title":"Reference","text":"","category":"section"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"CropSize\nRCropSize","category":"page"},{"location":"operations/size/cropsize/#Augmentor.CropSize","page":"CropSize","title":"Augmentor.CropSize","text":"CropSize <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area of the specified pixel size around the center of the input image.\n\nFor example the operation CropSize(10, 50) would denote a crop for a rectangle of height 10 and width 50 around the center of the input image.\n\nUsage\n\nCropSize(size)\n\nCropSize(size...)\n\nArguments\n\nsize : NTuple or Vararg of Int that denote the   output size in pixel for each dimension.\n\nSee also\n\nCropRatio, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# cropped around center of rotated image\naugment(img, Rotate(45) |> CropSize(300, 400))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropsize/#Augmentor.RCropSize","page":"CropSize","title":"Augmentor.RCropSize","text":"RCropSize <: Augmentor.ImageOperation\n\nDescription\n\nCrops out an area of predefined size at some random position of the given image.\n\nFor example the operation RCropSize(128, 64) denotes a random crop with height 128 and width 64. RCropSize(64) denotes a square shaped crop of size 64.\n\nUsage\n\nRCropSize(height, width)\n\nRCropSize(width)\n\nArguments\n\nheight::Number : Height of cropped region\nwidth::Number : Width of cropped region\n\nSee also\n\nRCropRatio, CropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop a randomly placed square of size 100\naugment(img, RCropSize(100))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"","category":"page"},{"location":"operations/size/cropsize/","page":"CropSize","title":"CropSize","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"interface/#High-level-Interface","page":"High-level Interface","title":"High-level Interface","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Integrating Augmentor into an existing project should in general not require any major changes to your code. In most cases it should break down to the three basic steps outlined below. We will spend the rest of this document investigating these in more detail.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Import Augmentor into the namespace of your program.\nusing Augmentor\nDefine a (stochastic) image processing pipeline by chaining the desired operations using |> and *.\njulia> pl = FlipX() * FlipY() |> Zoom(0.9:0.1:1.2) |> CropSize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Either: (50%) Flip the X axis. (50%) Flip the Y axis.\n 2.) Zoom by I ∈ {0.9×0.9, 1.0×1.0, 1.1×1.1, 1.2×1.2}\n 3.) Crop a 64×64 window around the center\nApply the pipeline to the existing image or set of images.\nimg_processed = augment(img_original, pl)","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Depending on the complexity of your problem, you may want to iterate between step 2. and 3. to identify an appropriate pipeline.","category":"page"},{"location":"interface/#pipeline","page":"High-level Interface","title":"Defining a Pipeline","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"In Augmentor, a (stochastic) image-processing pipeline can be understood as a sequence of operations, for which the parameters can (but need not) be random variables. What that essentially means is that the user explicitly specifies which image operation to perform in what order. A complete list of available operations can be found at Supported Operations.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"To start off with a simple example, let us assume that we want to first rotate our image(s) counter-clockwise by 14°, then crop them down to the biggest possible square, and lastly resize the image(s) to a fixed size of 64 by 64 pixel. Such a pipeline would be defined as follows:","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = Rotate(14) |> CropRatio(1) |> Resize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Rotate 14 degree\n 2.) Crop to 1:1 aspect ratio\n 3.) Resize to 64×64","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Notice that in the example above there is no room for randomness. In other words, the same input image would always result in the same output image given that pipeline. If we wish for more variation we can do so by using a vector as our parameters, instead of a single number.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"note: Note\nIn this subsection we will focus only on how to define a pipeline, without actually thinking too much about how to apply that pipeline to an actual image. The later will be the main topic of the rest of this document.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Say we wish to adapt our pipeline such that the rotation is a little more random. More specifically, lets say we want our image to be rotated by either -10°, -5°, 5°, 10°, or not at all. Other than that change we will leave the rest of the pipeline as is.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = Rotate([-10,-5,0,5,10]) |> CropRatio(1) |> Resize(64,64)\n3-step Augmentor.ImmutablePipeline:\n 1.) Rotate by θ ∈ [-10, -5, 0, 5, 10] degree\n 2.) Crop to 1:1 aspect ratio\n 3.) Resize to 64×64","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Variation in the parameters is only one of the two main ways to introduce randomness to our pipeline. Additionally, one can specify that an operation should be sampled randomly from a chosen set of operations . This can be accomplished using a utility operation called Either, which has its own convenience syntax.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"As an example, let us assume we wish to first either mirror our image(s) horizontally, or vertically, or not at all, and then crop it down to a size of 100 by 100 pixel around the image's center. We can specify the \"either\" using the * operator.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = FlipX() * FlipY() * NoOp() |> CropSize(100,100)\n2-step Augmentor.ImmutablePipeline:\n 1.) Either: (33%) Flip the X axis. (33%) Flip the Y axis. (33%) No operation.\n 2.) Crop a 100×100 window around the center","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"It is also possible to specify the odds of for such an \"either\". For example we may want the NoOp to be twice as likely as either of the mirroring options.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"julia> pl = (1=>FlipX()) * (1=>FlipY()) * (2=>NoOp()) |> CropSize(100,100)\n2-step Augmentor.ImmutablePipeline:\n 1.) Either: (25%) Flip the X axis. (25%) Flip the Y axis. (50%) No operation.\n 2.) Crop a 100×100 window around the center","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Now that we know how to define a pipeline, let us think about how to apply it to an image or a set of images.","category":"page"},{"location":"interface/#The-design-behind-operation-types","page":"High-level Interface","title":"The design behind operation types","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"The purpose of an operation is to simply serve as a \"dumb placeholder\" to specify the intent and parameters of the desired transformation. What that means is that a pipeline of operations can be thought of as a list of instructions (a cookbook of sorts), that Augmentor uses internally to construct the required code that implements the desired behaviour in the most efficient way it can.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"The way an operation is implemented depends on the rest of the specified pipeline. For example, Augmentor knows three different ways to implement the behaviour of the operation Rotate90 and will choose the one that best coincides with the other operations of the pipeline and their concrete order.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Call the function rotl90 of Julia's base library, which makes use of the fact that a 90 degree rotation can be implemented very efficiently. While by itself this is the fastest way to compute the result, this function is \"eager\" and will allocate a new array. If Rotate90 is followed by another operation this may not be the best choice, since it will cause a temporary image that is later discarded.\nCreate a SubArray of a PermutedDimsArray. This is more or less a lazy version of rotl90 that makes use of the fact that a 90 degree rotation can be described 1-to-1 using just the original pixels. By itself this strategy is slower than rotl90, but if it is followed by an operation such as Crop or CropSize it can be significantly faster. The reason for this is that it avoids the computation of unused pixels and also any allocation of temporary memory. The computation overhead per output pixel, while small, grows linearly with the number of chained operations.\nCreate an AffineMap using a rotation matrix that describes a 90 degree rotation around the center of the image. This will result in a lazy transformation of the original image that is further compose-able with other AffineMap. This is the slowest available strategy, unless multiple affine operations are chained together. If that is the case, then chaining the operations can be reduced to composing the tiny affine maps instead. This effectively fuses multiple operations into a single operation for which the computation overhead per output pixel remains approximately constant in respect to the number of chained operations.","category":"page"},{"location":"interface/#Loading-the-Example-Image","page":"High-level Interface","title":"Loading the Example Image","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Augmentor ships with a custom example image, which was specifically designed for visualizing augmentation effects. It can be accessed by calling the function testpattern(). That said, doing so explicitly should rarely be necessary in practice, because most high-level functions will default to using testpattern() if no other image is specified.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"testpattern","category":"page"},{"location":"interface/#Augmentor.testpattern","page":"High-level Interface","title":"Augmentor.testpattern","text":"testpattern([T=RGBA{N0f8}]; ratio=1.0) -> Matrix{RGBA{N0f8}}\n\nLoad and return the provided 300x400 test image. Additional args and kwargs are passed to imresize.\n\nThe returned image was specifically designed to be informative about the effects of the applied augmentation operations. It is thus well suited to prototype an augmentation pipeline, because it makes it easy to see what kind of effects one can achieve with it.\n\n\n\n\n\n","category":"function"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"using Augmentor\nimg = testpattern()\nusing Images; # hide\nsave(joinpath(\"assets\",\"big_pattern.png\"), img); # hide\nnothing # hide","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"(Image: testpattern)","category":"page"},{"location":"interface/#Augmenting-an-Image","page":"High-level Interface","title":"Augmenting an Image","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"Once a pipeline is constructed it can be applied to an image (i.e. AbstractArray{<:ColorTypes.Colorant}), or even just to an array of numbers (i.e. AbstractArray{<:Number}), using the function augment.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augment\nAugmentor.Mask","category":"page"},{"location":"interface/#Augmentor.augment","page":"High-level Interface","title":"Augmentor.augment","text":"augment([img], pipeline) -> out\naugment(img=>mask, pipeline) -> out\n\nApply the operations of the given pipeline sequentially to the given image img and return the resulting image out. For the second method, see Semantic wrappers below.\n\njulia> img = testpattern();\n\njulia> out = augment(img, FlipX() |> FlipY())\n3×2 Array{Gray{N0f8},2}:\n[...]\n\nThe parameter img can either be a single image, or a tuple of multiple images. In case img is a tuple of images, its elements will be assumed to be conceptually connected. Consequently, all images in the tuple will take the exact same path through the pipeline; even when randomness is involved. This is useful for the purpose of image segmentation, for which the input and output are both images that need to be transformed exactly the same way.\n\nimg1 = testpattern()\nimg2 = Gray.(testpattern())\nout1, out2 = augment((img1, img2), FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\nimg = testpattern()\naugment(img, FlipX() |> FlipY())\naugment(img, (FlipX(), FlipY()))\naugment(img, FlipX())\n\nIf img is omitted, Augmentor will use the augmentation test image provided by the function testpattern as the input image.\n\naugment(FlipX())\n\nSemantic wrappers\n\nIt is possible to define more flexible augmentation pipelines by wrapping the input into a semantic wrapper. Semantic wrappers determine meaning of an input, and ensure that only appropriate operations are applied on that input.\n\nCurrently implemented semantic wrappers are:\n\nAugmentor.Mask: Wraps a segmentation mask. Allows only spatial transformations.\nThe convenient usage for this is augment(img => mask, pipeline).\n\nExample\n\nusing Augmentor\nusing Augmentor: unwrap, Mask\n\nimg, mask = testpattern(), testpattern()\npl = Rotate90() |> GaussianBlur(3)\n\naug_img, aug_mask = unwrap.(augment((img, Mask(mask)), pl))\n# Equivalent usage\naug_img, aug_mask = augment(img => mask, pl)\n\n# GaussianBlur will be skipped for our `mask`\naug_mask == augment(mask, Rotate90())\n\n# output\n\ntrue\n\n\n\n\n\n","category":"function"},{"location":"interface/#Augmentor.Mask","page":"High-level Interface","title":"Augmentor.Mask","text":"Mask wraps a segmentation mask.\n\n\n\n\n\n","category":"type"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"We also provide a mutating version of augment that writes the output into preallocated memory. While this function avoids allocation, it does have the caveat that the size of the output image must be known beforehand (and thus must not be random).","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augment!","category":"page"},{"location":"interface/#Augmentor.augment!","page":"High-level Interface","title":"Augmentor.augment!","text":"augment!(out, img, pipeline) -> out\n\nApply the operations of the given pipeline sequentially to the image img and write the resulting image into the preallocated parameter out. For convenience out is also the function's return-value.\n\nimg = testpattern()\nout = similar(img)\naugment!(out, img, FlipX() |> FlipY())\n\nThe parameter img can either be a single image, or a tuple of multiple images. In case img is a tuple of images, the parameter out has to be a tuple of the same length and ordering. See augment for more information.\n\nimgs = (testpattern(), Gray.(testpattern()))\nouts = (similar(imgs[1]), similar(imgs[2]))\naugment!(outs, imgs, FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\nimg = testpattern()\nout = similar(img)\naugment!(out, img, FlipX() |> FlipY())\naugment!(out, img, (FlipX(), FlipY()))\naugment!(out, img, FlipX())\n\n\n\n\n\n","category":"function"},{"location":"interface/#Augmenting-Image-Batches","page":"High-level Interface","title":"Augmenting Image Batches","text":"","category":"section"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"In most machine learning scenarios we will want to process a whole batch of images at once, instead of a single image at a time. For this reason we provide the function augmentbatch!, which also supports multi-threading.","category":"page"},{"location":"interface/","page":"High-level Interface","title":"High-level Interface","text":"augmentbatch!","category":"page"},{"location":"interface/#Augmentor.augmentbatch!","page":"High-level Interface","title":"Augmentor.augmentbatch!","text":"augmentbatch!([resource], outs, imgs, pipeline, [obsdim]) -> outs\n\nApply the operations of the given pipeline to the images in imgs and write the resulting images into outs.\n\nBoth outs and imgs have to contain the same number of images. Each of these two variables can either be in the form of a higher dimensional array, in the form of a vector of arrays for which each vector element denotes an image.\n\n# create five example observations of size 3x3\nimgs = rand(3,3,5)\n# create output arrays of appropriate shape\nouts = similar(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\n\nIf one (or both) of the two parameters outs and imgs is a higher dimensional array, then the optional parameter obsdim can be used specify which dimension denotes the observations (defaults to ObsDim.Last()),\n\n# create five example observations of size 3x3\nimgs = rand(5,3,3)\n# create output arrays of appropriate shape\nouts = similar(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY(), ObsDim.First())\n\nSimilar to augment!, it is also allowed for outs and imgs to both be tuples of the same length. If that is the case, then each tuple element can be in any of the forms listed above. This is useful for tasks such as image segmentation, where each observations is made up of more than one image.\n\n# create five example observations where each observation is\n# made up of two conceptually linked 3x3 arrays\nimgs = (rand(3,3,5), rand(3,3,5))\n# create output arrays of appropriate shape\nouts = similar.(imgs)\n# transform the batch of images\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\n\nThe parameter pipeline can be a Augmentor.Pipeline, a tuple of Augmentor.Operation, or a single Augmentor.Operation.\n\naugmentbatch!(outs, imgs, FlipX() |> FlipY())\naugmentbatch!(outs, imgs, (FlipX(), FlipY()))\naugmentbatch!(outs, imgs, FlipX())\n\nThe optional first parameter resource can either be CPU1() (default) or CPUThreads(). In the later case the images will be augmented in parallel. For this to make sense make sure that the environment variable JULIA_NUM_THREADS is set to a reasonable number so that Threads.nthreads() is greater than 1.\n\n# transform the batch of images in parallel using multithreading\naugmentbatch!(CPUThreads(), outs, imgs, FlipX() |> FlipY())\n\n\n\n\n\n","category":"function"},{"location":"wrappers/#Semantic-Wrappers","page":"Semantic Wrappers","title":"Semantic Wrappers","text":"","category":"section"},{"location":"wrappers/","page":"Semantic Wrappers","title":"Semantic Wrappers","text":"Semantic wrappers are used to define a meaning of an input and consequently, determine what operations can be applied on that input.","category":"page"},{"location":"wrappers/","page":"Semantic Wrappers","title":"Semantic Wrappers","text":"Each semantic wrapper is expected to implement constructor which takes the original object and wraps it, and the Augmentor.unwrap method, which returns the wrapped object. I.e., for a wrapper W, the following holds: obj == unwrap(W(obj)).","category":"page"},{"location":"wrappers/","page":"Semantic Wrappers","title":"Semantic Wrappers","text":"To prevent name conflicts, it is suggested not to export any semantic wrappers.","category":"page"},{"location":"wrappers/","page":"Semantic Wrappers","title":"Semantic Wrappers","text":"Augmentor.SemanticWrapper\nAugmentor.unwrap","category":"page"},{"location":"wrappers/#Augmentor.SemanticWrapper","page":"Semantic Wrappers","title":"Augmentor.SemanticWrapper","text":"A SemanticWrapper determines the semantics of data that it wraps. Any subtype needs to implement function unwrap(wrapper) that returns the wrapped data.\n\n\n\n\n\n","category":"type"},{"location":"wrappers/#Augmentor.unwrap","page":"Semantic Wrappers","title":"Augmentor.unwrap","text":"unwrap(sw::SemanticWrapper)\n\nReturns the original object.\n\n\n\n\n\n","category":"function"},{"location":"operations/affine/zoom/#Zoom","page":"Zoom","title":"Zoom","text":"","category":"section"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Scale without resize","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"In the case that only a single Zoom factor is specified, the operation will assume that the intention is to Zoom all dimensions uniformly by that factor.","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"img_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Zoom(1.3)),\n    augment(img_in, Zoom(1.3, 1));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"It is also possible to pass some abstract vector(s) to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Random.seed!(1337)\nimg_out = [augment(img_in, Zoom(0.9:0.05:1.2)) for _ in 1:4]\n\nmosaicview(img_out...; nrow=2)","category":"page"},{"location":"operations/affine/zoom/#References","page":"Zoom","title":"References","text":"","category":"section"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"Zoom","category":"page"},{"location":"operations/affine/zoom/#Augmentor.Zoom","page":"Zoom","title":"Augmentor.Zoom","text":"Zoom <: Augmentor.ImageOperation\n\nDescription\n\nScales the image height and image width by the specified factors, but crops the image such that the original size is preserved.\n\nThe provided factors can either be numbers or vectors of numbers.\n\nIf numbers are provided, then the operation is deterministic and will always scale the input image with the same factors.\nIn the case vectors are provided, then each time the operation is applied a valid index is sampled and the elements corresponding to that index are used as scaling factors.\n\nIn contrast to Scale the size of the output image is the same as the size of the input image, while the content is scaled the same way. The same effect could be achieved by following a Scale with a CropSize, with the caveat that one would need to know the exact size of the input image before-hand.\n\nUsage\n\nZoom(factors)\n\nZoom(factors...)\n\nArguments\n\nfactors : NTuple or Vararg of Real or   AbstractVector that denote the scale factor(s) for each   array dimension. If only one variable is specified it is   assumed that height and width should be scaled by the same   factor(s).\n\nSee also\n\nScale, Resize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# half the image size\naugment(img, Zoom(0.5))\n\n# uniformly scale by a random factor from 1.2, 1.3, or 1.4\naugment(img, Zoom([1.2, 1.3, 1.4]))\n\n# scale by either 0.5x0.7 or by 0.6x0.8\naugment(img, Zoom([0.5, 0.6], [0.7, 0.8]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"","category":"page"},{"location":"operations/affine/zoom/","page":"Zoom","title":"Zoom","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/#operations","page":"Supported Operations","title":"Supported Operations","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Augmentor provides a wide variety of build-in image operations. This page provides an overview of all exported operations organized by their main category. These categories are chosen because they serve some practical purpose. For example Affine Operations allow for a special optimization under the hood when chained together.","category":"page"},{"location":"operations/#Affine-Transformations","page":"Supported Operations","title":"Affine Transformations","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"A sizeable amount of the provided operations fall under the category of affine transformations. As such, they can be described using what is known as an affine map, which are inherently compose-able if chained together. However, utilizing such a affine formulation requires (costly) interpolation, which may not always be needed to achieve the desired effect. For that reason do some of the operations below also provide a special purpose implementation to produce their specified result. Those are usually preferred over the affine formulation if sensible considering the complete pipeline.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"flip the input image horizontally or vertically","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Flip","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"rotate image anticlockwise","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Rotate","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"shear the input image horizontally or vertically","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Shear","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Relatively resizing image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Scale","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Set the static size of the image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Resize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Scale without resize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Zoom","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Distortions","page":"Supported Operations","title":"Distortions","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Aside from affine transformations, Augmentor also provides functionality for performing a variety of distortions. These types of operations usually provide a much larger distribution of possible output images.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Smoothed random distortion","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"ElasticDistortion","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Color-adjustments","page":"Supported Operations","title":"Color adjustments","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Adjust contrast and brightness of an image","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"ColorJitter","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Blurring","page":"Supported Operations","title":"Blurring","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"blur the input image using a gaussian kernel","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"GaussianBlur","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Resizing-and-Subsetting","page":"Supported Operations","title":"Resizing and Subsetting","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"The process of cropping is useful to discard parts of the input image. To provide this functionality lazily, applying a crop introduces a layer of representation called a \"view\" or SubArray. This is different yet compatible with how affine operations or other special purpose implementations work. This means that chaining a crop with some affine operation is perfectly fine if done sequentially. However, it is generally not advised to combine affine operations with crop operations within an Either block. Doing that would force the Either to trigger the eager computation of its branches in order to preserve type-stability.","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Subset image using Crop and CropNative","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop centered window to given size","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"CropSize","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Crop centered window to fit given aspect ratio","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"CropRatio","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/#Misc","page":"Supported Operations","title":"Misc","text":"","category":"section"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"a set of commonly used basic operations that wrapped by Augmentor","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Colorant conversion and channel layout","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"a set of helper operations that may be useful when compositing more complex augmentation workflow","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Composition utilities","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"a set of helper opeartions that allow applying any function","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"(Image: card-cover-image)","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"Higher-order functions","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>\n</div>","category":"page"},{"location":"operations/","page":"Supported Operations","title":"Supported Operations","text":"</div>","category":"page"},{"location":"gettingstarted/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"In this section we will provide a condensed overview of the package. In order to keep this overview concise, we will not discuss any background information or theory on the losses here in detail.","category":"page"},{"location":"gettingstarted/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To install Augmentor.jl, start up Julia and type the following code-snipped into the REPL. It makes use of the native Julia package manger.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.add(\"Augmentor\")","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Additionally, for example if you encounter any sudden issues, or in the case you would like to contribute to the package, you can manually choose to be on the latest (untagged) version.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Pkg.develop(\"Augmentor\")","category":"page"},{"location":"gettingstarted/#Example","page":"Getting Started","title":"Example","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The following code snippet shows how a stochastic augmentation pipeline can be specified using simple building blocks that we call \"operations\". In order to give the example some meaning, we will use a real medical image from the publicly available ISIC archive as input. The concrete image can be downloaded here using their Web API.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> using Augmentor, ISICArchive\n\njulia> img = get(ImageThumbnailRequest(id = \"5592ac599fc3c13155a57a85\"))\n169×256 Array{RGB{N0f8},2}:\n[...]\n\njulia> pl = Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()) |>\n            Rotate(0:360) |>\n            ShearX(-5:5) * ShearY(-5:5) |>\n            CropSize(165, 165) |>\n            Zoom(1:0.05:1.2) |>\n            Resize(64, 64)\n6-step Augmentor.ImmutablePipeline:\n 1.) Either: (25%) Flip the X axis. (25%) Flip the Y axis. (50%) No operation.\n 2.) Rotate by θ ∈ 0:360 degree\n 3.) Either: (50%) ShearX by ϕ ∈ -5:5 degree. (50%) ShearY by ψ ∈ -5:5 degree.\n 4.) Crop a 165×165 window around the center\n 5.) Zoom by I ∈ {1.0×1.0, 1.05×1.05, 1.1×1.1, 1.15×1.15, 1.2×1.2}\n 6.) Resize to 64×64\n\njulia> img_new = augment(img, pl)\n64×64 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using Augmentor, ISICArchive\nusing ImageCore, ImageMagick\nusing Random\n\nimg = get(ImageThumbnailRequest(id = \"5592ac599fc3c13155a57a85\"))\n\npl = Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()) |>\n     Rotate(0:360) |>\n     ShearX(-5:5) * ShearY(-5:5) |>\n     CropSize(165, 165) |>\n     Zoom(1:0.05:1.2) |>\n     Resize(64, 64)\n\n# modified from operations/assets/gif.jl\nfunction make_gif(img, pl, num_sample; post_op=identity, random_seed=1337)\n    Random.seed!(random_seed)\n\n    fillvalue = oneunit(eltype(img))\n    frames = sym_paddedviews(\n        fillvalue,\n        post_op(img),\n        [post_op(augment(img, pl)) for _ in 1:num_sample-1]...\n    )\n    cat(frames..., dims=3)\nend\n\nImageMagick.save(joinpath(\"assets\",\"isic_in.png\"), img)\npreview = make_gif(img, pl, 10)[:, :, 2:end]\nImageMagick.save(joinpath(\"assets\", \"isic_out.gif\"), preview; fps=2)\n\nnothing","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The function augment will generate a single augmented image from the given input image and pipeline. To visualize the effect we compiled a few resulting output images into a GIF.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Input (img)  Output (img_new)\n(Image: input) → (Image: output)","category":"page"},{"location":"gettingstarted/#Segmentation-example","page":"Getting Started","title":"Segmentation example","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Augmentor also provides a convenient interface for applying a stochastic augmentation for images and their masks, which is useful for tasks of semantic segmentation. The following snippet demonstrates how to use the interface. The used image is derived from the ISIC archive.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> using Augmentor\n\njulia> img, mask = # load image and its mask\n\njulia> pl = Either(Rotate90(), FlipX(), FlipY()) |>\n            Either(ColorJitter(), GaussianBlur(3))\n\njulia> img_new, mask_new = augment(img => mask, pl)","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using Augmentor\nusing FileIO, ImageMagick, ImageCore\nusing Random\n\nimgpath = joinpath(\"assets\",\"segm_img.png\")\nmaskpath = joinpath(\"assets\",\"segm_mask.png\")\n\nimg = load(imgpath)\nmask = load(maskpath)\n\npl = Either(Rotate90(), FlipX(), FlipY()) |>\n     Either(ColorJitter(), GaussianBlur(3))\n\n# modified from operations/assets/gif.jl\nfunction make_gif(img, mask, pl, num_sample; random_seed=1337)\n    Random.seed!(random_seed)\n\n    fillvalue = oneunit(eltype(img))\n    frames = sym_paddedviews(\n        fillvalue,\n        hcat(img, mask),\n        [hcat(augment(img => mask, pl)...) for _ in 1:num_sample-1]...\n    )\n    cat(frames..., dims=3)\nend\n\npreview = make_gif(img, mask, pl, 16)[:, :, 2:end]\nImageMagick.save(joinpath(\"assets\", \"segm_test.gif\"), preview; fps=2)\n\nnothing","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"The augmented images and masks are displayed in the following animation:","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"(Image: output)","category":"page"},{"location":"gettingstarted/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To get help on specific functionality you can either look up the information here, or if you prefer you can make use of Julia's native doc-system. The following example shows how to get additional information on augment within Julia's REPL:","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"?augment","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you find yourself stuck or have other questions concerning the package you can find us at gitter or the Machine Learning domain on discourse.julialang.org","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Julia ML on Gitter\nMachine Learning on Julialang","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you encounter a bug or would like to participate in the development of this package come find us on Github.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Evizero/Augmentor.jl","category":"page"},{"location":"operations/affine/shear/#Shear","page":"Shear","title":"Shear","text":"","category":"section"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"ShearX/ShearY can be used to shear the input image horizontally/vertically. The input to the constructor can be a scalar or a vector. In the case of a vector, the transformation will be a stochastic process.","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\nRandom.seed!(0)\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    # deterministic transformation\n    augment(img_in, ShearX(20)),\n    augment(img_in, ShearY(20)),\n\n    # random transformation\n    augment(img_in, ShearX(-20:20)),\n    augment(img_in, ShearY(-20:20));\n\n    fillvalue=colorant\"white\", nrow=2, npad=10\n)","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"Note that the output image size will be changed after transformation, CropNative can be particalually useful to preserve the image size.","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"mosaicview(\n    augment(img_in, ShearX(10)),\n    augment(img_in, ShearX(10) |> CropNative(axes(img_in)));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/shear/#References","page":"Shear","title":"References","text":"","category":"section"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"ShearX\nShearY","category":"page"},{"location":"operations/affine/shear/#Augmentor.ShearX","page":"Shear","title":"Augmentor.ShearX","text":"ShearX <: Augmentor.AffineOperation\n\nDescription\n\nShear the image horizontally for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIt will always perform the transformation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nShearX(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the shearing angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nShearY, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# shear horizontally exactly 5 degree\naugment(img, ShearX(5))\n\n# shear horizontally between 10 and 20 degree to the right\naugment(img, ShearX(10:20))\n\n# shear horizontally one of the five specified degrees\naugment(img, ShearX([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/shear/#Augmentor.ShearY","page":"Shear","title":"Augmentor.ShearY","text":"ShearY <: Augmentor.AffineOperation\n\nDescription\n\nShear the image vertically for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIt will always perform the transformation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nShearY(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the shearing angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nShearX, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# shear vertically exactly 5 degree\naugment(img, ShearY(5))\n\n# shear vertically between 10 and 20 degree upwards\naugment(img, ShearY(10:20))\n\n# shear vertically one of the five specified degrees\naugment(img, ShearY([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"","category":"page"},{"location":"operations/affine/shear/","page":"Shear","title":"Shear","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/crop/#Crop","page":"Crop","title":"Crop","text":"","category":"section"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Subset image using Crop and CropNative","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"using Augmentor\nusing ImageShow, ImageCore\nusing OffsetArrays\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, Crop(20:75,25:120))\n\nmosaicview(img_in, img_out; fillvalue=colorant\"white\", nrow=1)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"If the input image is plain arrays without offset indices, then Crop and CropNative is equivalent.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"augment(img_in, Crop(20:75,25:120)) == augment(img_in, CropNative(20:75,25:120))","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Whether you should use Crop or CropNative depends on if you want to take the index offset of the input image into consideration.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"imgo_in = OffsetArray(img_in, -50, -50)\nimgo_out = augment(imgo_in, Crop(20:75,25:120))\nimgo_out_native = augment(imgo_in, CropNative(20:75,25:120))\n\n(\n    imgo_in[(first.(axes(imgo_in)) .+ (20, 25))...] == imgo_out[1, 1],\n    imgo_in[20, 25] == imgo_out_native[1, 1]\n)","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"A typical scenario that you may want to use CropNative is when you have affine operations, e.g., Rotate and ShearX.","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"mosaicview(\n    augment(img_in, Rotate(30) |> Crop(axes(img_in))),\n    augment(img_in, Rotate(30) |> CropNative(axes(img_in))),\n\n    augment(img_in, ShearX(10) |> Crop(axes(img_in))),\n    augment(img_in, ShearX(10) |> CropNative(axes(img_in)));\n\n    fillvalue=colorant\"white\", rowmajor=true, nrow=2, npad=10\n)","category":"page"},{"location":"operations/size/crop/#Reference","page":"Crop","title":"Reference","text":"","category":"section"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"Crop\nCropNative","category":"page"},{"location":"operations/size/crop/#Augmentor.Crop","page":"Crop","title":"Augmentor.Crop","text":"Crop <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area denoted by the specified pixel ranges.\n\nFor example the operation Crop(5:100, 2:10) would denote a crop for the rectangle that starts at x=2 and y=5 in the top left corner and ends at x=10 and y=100 in the bottom right corner. As we can see the y-axis is specified first, because that is how the image is stored in an array. Thus the order of the provided axes ranges needs to reflect the order of the array dimensions.\n\nUsage\n\nCrop(indices)\n\nCrop(indices...)\n\nArguments\n\nindices : NTuple or Vararg of UnitRange that denote   the cropping range for each array dimension. This is very   similar to how the axes for view are specified.\n\nSee also\n\nCropNative, CropSize, CropRatio, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> augment(img, Crop(1:30, 361:400)) # crop upper right corner\n30×40 Array{RGBA{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/size/crop/#Augmentor.CropNative","page":"Crop","title":"Augmentor.CropNative","text":"CropNative <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the area denoted by the specified pixel ranges.\n\nFor example the operation CropNative(5:100, 2:10) would denote a crop for the rectangle that starts at x=2 and y=5 in the top left corner of native space and ends at x=10 and y=100 in the bottom right corner of native space.\n\nIn contrast to Crop, the position x=1 y=1 is not necessarily located at the top left of the current image, but instead depends on the cumulative effect of the previous transformations. The reason for this is because affine transformations are usually performed around the center of the image, which is reflected in \"native space\". This is useful for combining transformations such as Rotate or ShearX with a crop around the center area.\n\nUsage\n\nCropNative(indices)\n\nCropNative(indices...)\n\nArguments\n\nindices : NTuple or Vararg of UnitRange that denote   the cropping range for each array dimension. This is very   similar to how the axes for view are specified.\n\nSee also\n\nCrop, CropSize, CropRatio, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# cropped at top left corner\naugment(img, Rotate(45) |> Crop(1:300, 1:400))\n\n# cropped around center of rotated image\naugment(img, Rotate(45) |> CropNative(1:300, 1:400))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"","category":"page"},{"location":"operations/size/crop/","page":"Crop","title":"Crop","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/blur/gaussianblur/#GaussianBlur","page":"GaussianBlur","title":"GaussianBlur","text":"","category":"section"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"GaussianBlur can be used to blur the input image using a gaussian kernel with a specified kernel size and standard deviation.","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, GaussianBlur(3)),\n    augment(img_in, GaussianBlur(5, 2.5));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/blur/gaussianblur/#References","page":"GaussianBlur","title":"References","text":"","category":"section"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"GaussianBlur","category":"page"},{"location":"operations/blur/gaussianblur/#Augmentor.GaussianBlur","page":"GaussianBlur","title":"Augmentor.GaussianBlur","text":"GaussianBlur <: ColorOperation\n\nDescription\n\nBlurs an image using a Gaussian filter.\n\nUsage\n\nGaussianBlur(k, [σ])\n\nArguments\n\nk : Integer or AbstractVector of Integer that denote   the kernel size. It must be an odd positive number.\nσ : Optional. Real or AbstractVector of Real that denote the   standard deviation. It must be a positive number.   Defaults to 0.3 * ((k - 1) / 2 - 1) + 0.8.\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# use exactly k=3 and σ=1.0\naugment(img, GaussianBlur(3, 1.0))\n\n# pick k and σ randomly from the specified ranges\naugment(img, GaussianBlur(3:2:7, 1.0:0.1:2.0))\n\n\n\n\n\n","category":"type"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"","category":"page"},{"location":"operations/blur/gaussianblur/","page":"GaussianBlur","title":"GaussianBlur","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/color/colorjitter/#ColorJitter","page":"ColorJitter","title":"ColorJitter","text":"","category":"section"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"ColorJitter can be used to adjust the contrast and brightness of an input image.","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, ColorJitter(1.2, 0.3)),\n    augment(img_in, ColorJitter(0.75, -0.2));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/color/colorjitter/#References","page":"ColorJitter","title":"References","text":"","category":"section"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"ColorJitter","category":"page"},{"location":"operations/color/colorjitter/#Augmentor.ColorJitter","page":"ColorJitter","title":"Augmentor.ColorJitter","text":"ColorJitter <: ColorOperation\n\nDescription\n\nAdjusts the brightness and contrast of an image according to the formula α * image[i] + β * M, where M is either mean(image) or the maximum intensity value.\n\nUsage\n\nColorJitter()\nColorJitter(α, β; [usemax])\n\nArguments\n\nα : Real or AbstractVector of Real that denote the coefficient(s)   for contrast adjustment. Defaults to 0.8:0.1:1.2.\nβ : Real or AbstractVector of Real that denote the coefficient(s)   for brightness adjustment. Defaults to -0.2:0.1:0.2.\nusemax::Bool: Optional. If true, the brightness will be adjusted by   the maximum intensity value; otherwise, the image mean will be used.   Defaults to true.\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# use exactly 1.2 for contrast, and one of 0.5 and 0.8 for brightness\naugment(img, ColorJitter(1.2, [0.5, 0.8]))\n\n# pick the coefficients randomly from the specified ranges\naugment(img, ColorJitter(0.8:0.1:2.0, 0.5:0.1:1.1))\n\n\n\n\n\n","category":"type"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"","category":"page"},{"location":"operations/color/colorjitter/","page":"ColorJitter","title":"ColorJitter","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/distortions/elasticdistortion/#op_elastic","page":"ElasticDistortion","title":"ElasticDistortion","text":"","category":"section"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"Smoothed random distortion","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, ElasticDistortion(15,15,0.1)),\n    augment(img_in, ElasticDistortion(10,10,0.2,4,3,true));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/distortions/elasticdistortion/#Reference","page":"ElasticDistortion","title":"Reference","text":"","category":"section"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"ElasticDistortion","category":"page"},{"location":"operations/distortions/elasticdistortion/#Augmentor.ElasticDistortion","page":"ElasticDistortion","title":"Augmentor.ElasticDistortion","text":"ElasticDistortion <: Augmentor.ImageOperation\n\nDescription\n\nDistorts the given image using a randomly (uniform) generated vector field of the given grid size. This field will be stretched over the given image when applied, which in turn will morph the original image into a new image using a linear interpolation of both the image and the vector field.\n\nIn contrast to [RandomDistortion], the resulting vector field is also smoothed using a Gaussian filter with of parameter sigma. This will result in a less chaotic vector field and thus resemble a more natural distortion.\n\nUsage\n\nElasticDistortion(gridheight, gridwidth, scale, sigma, [iter=1], [border=false], [norm=true])\n\nElasticDistortion(gridheight, gridwidth, scale; [sigma=2], [iter=1], [border=false], [norm=true])\n\nElasticDistortion(gridheight, [gridwidth]; [scale=0.2], [sigma=2], [iter=1], [border=false], [norm=true])\n\nArguments\n\ngridheight : The grid height of the displacement vector   field. This effectively specifies the number of vertices   along the Y dimension used as landmarks, where all the   positions between the grid points are interpolated.\ngridwidth : The grid width of the displacement vector   field. This effectively specifies the number of vertices   along the Y dimension used as landmarks, where all the   positions between the grid points are interpolated.\nscale : Optional. The scaling factor applied to all   displacement vectors in the field. This effectively defines   the \"strength\" of the deformation. There is no theoretical   upper limit to this factor, but a value somewhere between   0.01 and 1.0 seem to be the most reasonable choices.   Default to 0.2.\nsigma : Optional. Sigma parameter of the Gaussian filter.   This parameter effectively controls the strength of the   smoothing. Defaults to 2.\niter : Optional. The number of times the smoothing   operation is applied to the displacement vector field. This   is especially useful if border = false because the border   will be reset to zero after each pass. Thus the displacement   is a little less aggressive towards the borders of the image   than it is towards its center. Defaults to   1.\nborder : Optional. Specifies if the borders should be   distorted as well. If false, the borders of the image will   be preserved. This effectively pins the outermost vertices on   their original position and the operation thus only distorts   the inner content of the image. Defaults to   false.\nnorm : Optional. If true, the displacement vectors of   the field will be normalized by the norm of the field. This   will have the effect that the scale factor should be more   or less independent of the grid size. Defaults to   true.\n\nSee also\n\naugment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# distort with pinned borders\naugment(img, ElasticDistortion(15, 15; scale = 0.1))\n\n# distort everything more smoothly.\naugment(img, ElasticDistortion(10, 10; sigma = 4, iter=3, border=true))\n\n\n\n\n\n","category":"type"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"","category":"page"},{"location":"operations/distortions/elasticdistortion/","page":"ElasticDistortion","title":"ElasticDistortion","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"license/#License","page":"License","title":"License","text":"","category":"section"},{"location":"license/","page":"License","title":"License","text":"using Markdown, Augmentor\nMarkdown.parse_file(joinpath(pkgdir(Augmentor), \"LICENSE.md\"))","category":"page"},{"location":"operations/misc/layout/#Colorant-conversion-and-channel-layout","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"","category":"section"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"Augmentor has warpped some commonly used basic operations so that you can use to build the augmentation pipeline. The internal column is what you'd probably do outside of Augmentor.","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"Category internal Augmentor\nConversion T.(img) ConvertEltype(T)\nInformation Layout ImageCore.channelview SplitChannels\nInformation Layout ImageCore.colorview CombineChannels\nInformation Layout Base.permutedims PermuteDims\nInformation Layout Base.reshape Reshape","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"It is not uncommon that machine learning frameworks require the data in a specific form and layout. For example many deep learning frameworks expect the colorchannel of the images to be encoded in the third dimension of a 4-dimensional array. Augmentor allows to convert from (and to) these different layouts using special operations that are mainly useful in the beginning or end of a augmentation pipeline.","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"using Augmentor\nusing ImageCore\n\n# 300×400 Matrix{RGB{N0f8}, 2} => 300×400×3 Array{Float32, 3}\nimg = testpattern(RGB, ratio=0.5)\nimg_in = augment(img, SplitChannels() |> PermuteDims(2, 3, 1) |> ConvertEltype(Float32))\n\n# 300×400×3 Array{Float32, 3} => 300×400 Matrix{RGB{N0f8}, 2}\nimg_out = augment(img_in, ConvertEltype(N0f8) |> PermuteDims(3, 1, 2) |> CombineChannels(RGB))\n\nimg_out == img","category":"page"},{"location":"operations/misc/layout/#References","page":"Colorant conversion and channel layout","title":"References","text":"","category":"section"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"ConvertEltype\nSplitChannels\nCombineChannels\nPermuteDims\nReshape","category":"page"},{"location":"operations/misc/layout/#Augmentor.ConvertEltype","page":"Colorant conversion and channel layout","title":"Augmentor.ConvertEltype","text":"ConvertEltype <: Augmentor.Operation\n\nDescription\n\nConvert the element type of the given array/image into the given eltype. This operation is especially useful for converting color images to grayscale (or the other way around). That said, the operation is not specific to color types and can also be used for numeric arrays (e.g. with separated channels).\n\nNote that this is an element-wise convert function. Thus it can not be used to combine or separate color channels. Use SplitChannels or CombineChannels for those purposes.\n\nUsage\n\nConvertEltype(eltype)\n\nArguments\n\neltype : The eltype of the resulting array/image.\n\nSee also\n\nCombineChannels, SplitChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(RGB, 10, 10) # three color channels\n10×10 Array{RGB{Float64},2}:\n[...]\n\njulia> augment(A, ConvertEltype(Gray{Float32})) # convert to grayscale\n10×10 Array{Gray{Float32},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.SplitChannels","page":"Colorant conversion and channel layout","title":"Augmentor.SplitChannels","text":"SplitChannels <: Augmentor.Operation\n\nDescription\n\nSplits out the color channels of the given image using the function ImageCore.channelview. This will effectively create a new array dimension for the colors in the front. In contrast to ImageCore.channelview it will also result in a new dimension for gray images.\n\nThis operation is mainly useful at the end of a pipeline in combination with PermuteDims in order to prepare the image for the training algorithm, which often requires the color channels to be separate.\n\nUsage\n\nSplitChannels()\n\nSee also\n\nPermuteDims, CombineChannels, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> augment(img, SplitChannels())\n4×300×400 Array{N0f8,3}:\n[...]\n\njulia> augment(img, SplitChannels() |> PermuteDims(3,2,1))\n400×300×4 Array{N0f8,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.CombineChannels","page":"Colorant conversion and channel layout","title":"Augmentor.CombineChannels","text":"CombineChannels <: Augmentor.Operation\n\nDescription\n\nCombines the first dimension of a given array into a colorant of type colortype using the function ImageCore.colorview. The main difference is that a separate color channel is also expected for Gray images.\n\nThe shape of the input image has to be appropriate for the given colortype, which also means that the separated color channel has to be the first dimension of the array. See PermuteDims if that is not the case.\n\nUsage\n\nCombineChannels(colortype)\n\nArguments\n\ncolortype : The color type of the resulting image. Must   be a subtype of ColorTypes.Colorant and match the color   channel of the given image.\n\nSee also\n\nSplitChannels, PermuteDims, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(3, 10, 10) # three color channels\n3×10×10 Array{Float64,3}:\n[...]\n\njulia> augment(A, CombineChannels(RGB))\n10×10 Array{RGB{Float64},2}:\n[...]\n\njulia> B = rand(1, 10, 10) # singleton color channel\n1×10×10 Array{Float64,3}:\n[...]\n\njulia> augment(B, CombineChannels(Gray))\n10×10 Array{Gray{Float64},2}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.PermuteDims","page":"Colorant conversion and channel layout","title":"Augmentor.PermuteDims","text":"PermuteDims <: Augmentor.Operation\n\nDescription\n\nPermute the dimensions of the given array with the predefined permutation perm. This operation is particularly useful if the order of the dimensions needs to be different than the default \"julian\" layout (described below).\n\nAugmentor expects the given images to be in vertical-major layout for which the colors are encoded in the element type itself. Many deep learning frameworks however require their input in a different order. For example it is not untypical that separate color channels are expected to be encoded in the third dimension.\n\nUsage\n\nPermuteDims(perm)\n\nPermuteDims(perm...)\n\nArguments\n\nperm : The concrete dimension permutation that should be   used. Has to be specified as a Vararg{Int} or as a NTuple   of Int. The length of perm has to match the number of   dimensions of the expected input image to that operation.\n\nSee also\n\nSplitChannels, CombineChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(10, 5, 3) # width=10, height=5, and 3 color channels\n10×5×3 Array{Float64,3}:\n[...]\n\njulia> img = augment(A, PermuteDims(3,2,1) |> CombineChannels(RGB))\n5×10 Array{RGB{Float64},2}:\n[...]\n\njulia> img2 = testpattern()\n300×400 Array{RGBA{N0f8},2}:\n[...]\n\njulia> B = augment(img2, SplitChannels() |> PermuteDims(3,2,1))\n400×300×4 Array{N0f8,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/#Augmentor.Reshape","page":"Colorant conversion and channel layout","title":"Augmentor.Reshape","text":"Reshape <: Augmentor.Operation\n\nDescription\n\nReinterpret the shape of the given array of numbers or colorants. This is useful for example to create singleton-dimensions that deep learning frameworks may need for colorless images, or for converting an image array to a feature vector (and vice versa).\n\nUsage\n\nReshape(dims)\n\nReshape(dims...)\n\nArguments\n\ndims : The new sizes for each dimension of the output   image. Has to be specified as a Vararg{Int} or as a   NTuple of Int.\n\nSee also\n\nCombineChannels, augment\n\nExamples\n\njulia> using Augmentor, Colors\n\njulia> A = rand(10,10)\n10×10 Array{Float64,2}:\n[...]\n\njulia> augment(A, Reshape(10,10,1)) # add trailing singleton dimension\n10×10×1 Array{Float64,3}:\n[...]\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"","category":"page"},{"location":"operations/misc/layout/","page":"Colorant conversion and channel layout","title":"Colorant conversion and channel layout","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/affine/resize/#Resize","page":"Resize","title":"Resize","text":"","category":"section"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"Set the static size of the image","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\n\nmosaicview(\n    img_in,\n    augment(img_in, Resize(240, 320));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/resize/#References","page":"Resize","title":"References","text":"","category":"section"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"Resize","category":"page"},{"location":"operations/affine/resize/#Augmentor.Resize","page":"Resize","title":"Augmentor.Resize","text":"Resize <: Augmentor.ImageOperation\n\nDescription\n\nRescales the image to a fixed pre-specified pixel size.\n\nThis operation does not take any measures to preserve aspect ratio of the source image. Instead, the original image will simply be resized to the given dimensions. This is useful when one needs a set of images to all be of the exact same size.\n\nUsage\n\nResize(; height=64, width=64)\n\nResize(size)\n\nResize(size...)\n\nArguments\n\nsize : NTuple or Vararg of Int that denote the   output size in pixel for each dimension.\n\nSee also\n\nCropSize, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\naugment(img, Resize(30, 40))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"","category":"page"},{"location":"operations/affine/resize/","page":"Resize","title":"Resize","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/misc/utilities/#Composition-utilities","page":"Composition utilities","title":"Composition utilities","text":"","category":"section"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"Aside from \"true\" operations that specify some kind of transformation, there are also a couple of special utility operations used for functionality such as stochastic branching.","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"using Augmentor\nusing Random\nRandom.seed!(1337)\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, Either(0.5=>NoOp(), 0.25=>FlipX(), 0.25=>FlipY()))\nnothing #hide","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"(Image: )","category":"page"},{"location":"operations/misc/utilities/#References","page":"Composition utilities","title":"References","text":"","category":"section"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"NoOp\nEither\nCacheImage","category":"page"},{"location":"operations/misc/utilities/#Augmentor.NoOp","page":"Composition utilities","title":"Augmentor.NoOp","text":"NoOp <: Augmentor.AffineOperation\n\nIdentity transformation that does not do anything with the given image, but instead passes it along unchanged (without copying).\n\nUsually used in combination with Either to denote a \"branch\" that does not perform any computation.\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/#Augmentor.Either","page":"Composition utilities","title":"Augmentor.Either","text":"Either <: Augmentor.ImageOperation\n\nDescription\n\nChooses between the given operations at random when applied. This is particularly useful if one for example wants to first either rotate the image 90 degree clockwise or anticlockwise (but never both), and then apply some other operation(s) afterwards.\n\nWhen compiling a pipeline, Either will analyze the provided operations in order to identify the preferred formalism to use when applied. The chosen formalism is chosen such that it is supported by all given operations. This way the output of applying Either will be inferable and the whole pipeline will remain type-stable (even though randomness is involved).\n\nBy default each specified image operation has the same probability of occurrence. This default behaviour can be overwritten by specifying the chance manually.\n\nUsage\n\nEither(operations, [chances])\n\nEither(operations...; [chances])\n\nEither(pairs...)\n\n*(operations...)\n\n*(pairs...)\n\nArguments\n\noperations : NTuple or Vararg of Augmentor.ImageOperation   that denote the possible choices to sample from when applied.\nchances : Optional. Denotes the relative chances for an   operation to be sampled. Has to contain the same number of   elements as operations. Either an NTuple of numbers if   specified as positional argument, or alternatively a   AbstractVector of numbers if specified as a keyword   argument. If omitted every operation will have equal   probability of occurring.\npairs : Vararg of Pair{<:Real,<:Augmentor.ImageOperation}.   A compact way to specify an operation and its chance of   occurring together.\n\nSee also\n\nNoOp, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# all three operations have equal chance of occuring\naugment(img, Either(FlipX(), FlipY(), NoOp()))\naugment(img, FlipX() * FlipY() * NoOp())\n\n# NoOp is twice as likely as either FlipX or FlipY\naugment(img, Either(1=>FlipX(), 1=>FlipY(), 2=>NoOp()))\naugment(img, Either(FlipX(), FlipY(), NoOp(), chances=[1,1,2]))\naugment(img, Either((FlipX(), FlipY(), NoOp()), (1,1,2)))\naugment(img, (1=>FlipX()) * (1=>FlipY()) * (2=>NoOp()))\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/#Augmentor.CacheImage","page":"Composition utilities","title":"Augmentor.CacheImage","text":"CacheImage <: Augmentor.ImageOperation\n\nDescription\n\nWrite the current state of the image into the working memory. Optionally a user has the option to specify a preallocated buffer to write the image into. Note that if a buffer is provided, then it has to be of the correct size and eltype.\n\nEven without a preallocated buffer it can be beneficial in some situations to cache the image. An example for such a scenario is when chaining a number of affine transformations after an elastic distortion, because performing that lazily requires nested interpolation.\n\nUsage\n\nCacheImage()\n\nCacheImage(buffer)\n\nArguments\n\nbuffer : Optional. A preallocated AbstractArray of the   appropriate size and eltype.\n\nSee also\n\naugment\n\nExamples\n\nusing Augmentor\n\n# make pipeline that forces caching after elastic distortion\npl = ElasticDistortion(3,3) |> CacheImage() |> Rotate(-10:10) |> ShearX(-5:5)\n\n# cache output of elastic distortion into the allocated\n# 20x20 Matrix{Float64}. Note that for this case this assumes that\n# the input image is also a 20x20 Matrix{Float64}\npl = ElasticDistortion(3,3) |> CacheImage(zeros(20,20)) |> Rotate(-10:10)\n\n# convenience syntax with the same effect as above.\npl = ElasticDistortion(3,3) |> zeros(20,20) |> Rotate(-10:10)\n\n\n\n\n\n","category":"type"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"","category":"page"},{"location":"operations/misc/utilities/","page":"Composition utilities","title":"Composition utilities","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/flux/#Integration-with-Flux.jl","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"","category":"section"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"This example shows a way to use Augmentor to provide images for training Flux.jl models. We will be using the MNIST database of handwritten digits as our input data.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"To skip all the talking and see the code, go ahead to Complete example.","category":"page"},{"location":"examples/flux/#Ordinary-training","page":"Integration with Flux.jl","title":"Ordinary training","text":"","category":"section"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"Let's first show how training looks without any augmentation.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"We are using the MLDataSets.jl package to coveniently access the MNIST dataset. To reduce the training time, we are working only with a subset of the data.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"After collecting the data, we divide them into batches using batchview from MLDataUtils.jl. We then create a model, pick a loss function and an optimizer, and start the training.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"using Flux, MLDatasets, MLDataUtils\n\nn_instances = 32\nbatch_size = 32\nn_epochs = 16\n\n# Flux requires a 4D numerical array in WHCN (width, height, channel, batch)\n# format thus we need to insert a dummy dimension to indicate `C=1`(gray image).\nX = Flux.unsqueeze(MNIST.traintensor(Float32, 1:n_instances), 3)\ny = Flux.onehotbatch(MNIST.trainlabels(1:n_instances), 0:9)\n\n# size(X) == (28, 28, 1, 32)\n# size(y) == (10, 32)\n@assert size(X) == (28, 28, 1, 32) # hide\n@assert size(y) == (10, 32) # hide\n\n# `data = batches[1]` means the first batch input:\n#     - `data[1]` is a batch extracted from `X`\n#     - `data[2]` is a batch extracted from `y`\n# We also apply `shuffleobs` to get a random batch view.\nbatches = batchview(shuffleobs((X, y)), maxsize=batch_size)\n\npredict = Chain(Conv((3, 3), 1=>16, pad=(1, 1), relu),\n                MaxPool((2,2)),\n                Conv((3, 3), 16=>32, pad=(1, 1), relu),\n                MaxPool((2,2)),\n                Conv((3, 3), 32=>32, pad=(1, 1), relu),\n                MaxPool((2, 2)),\n                flatten,\n                Dense(288, 10))\n\nloss(X, y) = Flux.Losses.logitcrossentropy(predict(X), y)\n\nopt = Flux.Optimise.ADAM(0.001)\n\nfor epoch in 1:n_epochs\n    Flux.train!(loss, params(predict), batches, opt)\nend\n\nnothing # hide","category":"page"},{"location":"examples/flux/#Adding-augmentation","page":"Integration with Flux.jl","title":"Adding augmentation","text":"","category":"section"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"Augmentor aims to provide generic image augmentation support for any machine learning framework and not just deep learning. Except for the grayscale images, Augmentor assumes every image is an array of Colorant. Without loss of generality, we use Gray image here so that the same pipeline also applies to RGB image.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"warning: Use colorant array whenever you can\nIf you pass a 3d numerical array, e.g., of size (28, 28, 3) and interpret it as an RGB array, you'll almost definitely get an incorrect result from Augmentor. This is because Augmentor and the entire JuliaImages ecosystem uses Array{RGB{Float32}, 2} to represent an RGB array. Without any explicit note, Array{Float32, 3} will be interpreted as a 3d gray image instead of any colorful image. Just think of the color specifications like Lab, HSV and you'll notice the ambiguity here.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"using ImageCore\n\nX = Gray.(MNIST.traintensor(Float32, 1:n_instances))\ny = Flux.onehotbatch(MNIST.trainlabels(1:n_instances), 0:9)\n\nnothing # hide","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"Augmentation is given by an augmentation pipeline. Our pipeline is a composition of three operations:","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"ElasticDistortion is the only image operation in this pipeline.\nSplitChannels split the colorant array into the plain numerical array so that deep learning frameworks are happy with the layout.\nPermuteDims permutes the dimension of each image to match WHC.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"The operations are composed by the |> operator.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"using Augmentor\n\npl = ElasticDistortion(6, 6,\n                       sigma=4,\n                       scale=0.3,\n                       iter=3,\n                       border=true) |>\n     SplitChannels() |>\n     PermuteDims((2, 3, 1))","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"Next, we define two helper functions.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"# Creates an output array for augmented images\noutbatch(X) = Array{Float32}(undef, (28, 28, 1, nobs(X)))\n# Takes a batch (images and targets) and augments the images\naugmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)\n\nnothing # hide","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"In many deep learning tasks, the augmentation is applied lazily during the data iteration. For this purpose, we wrap the batches with a mapped array in order to augment each batch right before feeding it to the network.","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"using MappedArrays\n\nbatches = batchview((X, y), maxsize=batch_size)\nbatches = mappedarray(augmentbatch, batches)\n# eager alternative: augmentation happens when this line gets executed\n# batches = augmentbatch.(batches)\n\n# The output is already in the expected WHCN format\n# size(batches[1][1]) == (28, 28, 1, 32)\n# size(batches[1][2]) == (10, 32)\n@assert size(batches[1][1]) == (28, 28, 1, 32) # hide\n@assert size(batches[1][2]) == (10, 32) # hide\n\nnothing # hide","category":"page"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"Iterating over batches will now produce augmented images. No other changes are required.","category":"page"},{"location":"examples/flux/#flux_mnist_complete_example","page":"Integration with Flux.jl","title":"Complete example","text":"","category":"section"},{"location":"examples/flux/","page":"Integration with Flux.jl","title":"Integration with Flux.jl","text":"using Augmentor, Flux, ImageCore, MappedArrays, MLDatasets, MLDataUtils\n\nn_instances = 32\nbatch_size = 32\nn_epochs = 16\n\nX = Gray.(MNIST.traintensor(Float32, 1:n_instances))\ny = Flux.onehotbatch(MNIST.trainlabels(1:n_instances), 0:9)\n\npl = ElasticDistortion(6, 6,\n                       sigma=4,\n                       scale=0.3,\n                       iter=3,\n                       border=true) |>\n     SplitChannels() |>\n     PermuteDims((2, 3, 1))\n\noutbatch(X) = Array{Float32}(undef, (28, 28, 1, nobs(X)))\naugmentbatch((X, y)) = (augmentbatch!(outbatch(X), X, pl), y)\n\nbatches = mappedarray(augmentbatch, batchview((X, y), maxsize=batch_size))\n\npredict = Chain(Conv((3, 3), 1=>16, pad=(1, 1), relu),\n                MaxPool((2,2)),\n                Conv((3, 3), 16=>32, pad=(1, 1), relu),\n                MaxPool((2,2)),\n                Conv((3, 3), 32=>32, pad=(1, 1), relu),\n                MaxPool((2, 2)),\n                flatten,\n                Dense(288, 10))\n\nloss(X, y) = Flux.Losses.logitcrossentropy(predict(X), y)\n\nopt = Flux.Optimise.ADAM(0.001)\n\nfor epoch in 1:n_epochs\n    Flux.train!(loss, params(predict), batches, opt)\nend","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: header)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"A fast library for increasing the number of training images by applying various transformations.","category":"page"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Augmentor is a real-time image augmentation library designed to render the process of artificial dataset enlargement more convenient, less error prone, and easier to reproduce. It offers the user the ability to build a stochastic image-processing pipeline (or simply augmentation pipeline) using image operations as building blocks. In other words, an augmentation pipeline is little more but a sequence of operations for which the parameters can (but need not) be random variables, as the following code snippet demonstrates.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Augmentor\npl = ElasticDistortion(6, scale=0.3, border=true) |>\n     Rotate([10, -5, -3, 0, 3, 5, 10]) |>\n     ShearX(-10:10) * ShearY(-10:10) |>\n     CropSize(28, 28) |>\n     Zoom(0.9:0.1:1.2)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Such a pipeline can then be used for sampling. Here we use the first few examples of the MNIST database.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Augmentor, ImageCore, ImageMagick\nusing MLDatasets\nusing Random\n\n# copied from operations/assets/gif.jl\nfunction make_gif(img, pl, num_sample; random_seed=1337, kwargs...)\n    fillvalue = oneunit(eltype(img[1]))\n\n    init_frame = mosaicview(img; kwargs...)\n    frames = map(1:num_sample-1) do _\n        mosaicview(map(x->augment(x, pl), img)...; kwargs...)\n    end\n\n    frames = sym_paddedviews(fillvalue, init_frame, frames...)\n    cat(frames..., dims=3)\nend\n\npl = ElasticDistortion(6, scale=0.3, border=true) |>\n     Rotate([10, -5, -3, 0, 3, 5, 10]) |>\n     ShearX(-10:10) * ShearY(-10:10) |>\n     CropSize(28, 28) |>\n     Zoom(0.9:0.1:1.2)\n\nn_samples, n_frames = 24, 10\nimgs = [MNIST.convert2image(MNIST.traintensor(i)) for i in 1:n_samples]\npreview = make_gif(imgs, pl, n_frames; nrow=1)\n\nImageMagick.save(\"mnist_preview.gif\", RGB(1, 1, 1) .- preview; fps=3)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: mnist_preview)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The Julia version of Augmentor is engineered specifically for high performance applications. It makes use of multiple heuristics to generate efficient tailor-made code for the concrete user-specified augmentation pipeline. In particular Augmentor tries to avoid the need for any intermediate images, but instead aims to compute the output image directly from the input in one single pass.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For the Python version of Augmentor, you can find it here","category":"page"},{"location":"#What-is-Image-Augmentation?","page":"Introduction","title":"What is Image Augmentation?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The term data augmentation is commonly used to describe the process of repeatedly applying various transformations to some dataset, with the hope that the output (i.e. the newly generated observations) bias the model towards learning better features. Depending on the structure and semantics of the data, coming up with such transformations can be a challenge by itself.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Images are a special class of data that exhibit some interesting properties in respect to their structure. For example the dimensions of an image (i.e. the pixel) exhibit a spatial relationship to each other. As such, a lot of commonly used augmentation strategies for image data revolve around affine transformations, such as translations or rotations. Because images are so popular and special case of data, they deserve their own sub-category of data augmentation, which we will unsurprisingly refer to as image augmentation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The general idea is the following: if we want our model to generalize well, then we should design the learning process in such a way as to bias the model into learning such transformation-equivariant properties. One way to do this is via the design of the model itself, which for example was idea behind convolutional neural networks. An orthogonal approach to bias the model to learn about this equivariance - and the focus of this package - is by using label-preserving transformations.","category":"page"},{"location":"#labelpreserving","page":"Introduction","title":"Label-preserving Transformations","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Before attempting to train a model using some augmentation pipeline, it's a good idea to invest some time in deciding on an appropriate set of transformations to choose from. Some of these transformations also have parameters to tune, and we should also make sure that we settle on a decent set of values for those.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"What constitutes as \"decent\" depends on the dataset. In general we want the augmented images to be fairly dissimilar to the originals. However, we need to be careful that the augmented images still visually represent the same concept (and thus label). If a pipeline only produces output images that have this property we call this pipeline label-preserving.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Consider the following example from the MNIST database of handwritten digits. Our input image clearly represents its associated label \"6\". If we were to use the transformation Rotate180 in our augmentation pipeline for this type of images, we could end up with the situation depicted by the image on the right side.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Augmentor, MLDatasets\ninput_img  = MNIST.convert2image(MNIST.traintensor(19))\noutput_img = augment(input_img, Rotate180())\nusing Images, FileIO; # hide\nupsize(A) = repeat(A, inner=(4,4)); # hide\nsave(joinpath(\"assets\",\"bg_mnist_in.png\"), upsize(input_img)); # hide\nsave(joinpath(\"assets\",\"bg_mnist_out.png\"), upsize(output_img)); # hide\nnothing # hide","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Input (input_img) Output (output_img)\n(Image: input) (Image: output)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"To a human, this newly transformed image clearly represents the label \"9\", and not \"6\" like the original image did. In image augmentation, however, the assumption is that the output of the pipeline has the same label as the input. That means that in this example we would tell our model that the correct answer for the image on the right side is \"6\", which is clearly undesirable for obvious reasons.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Thus, for the MNIST dataset, the transformation Rotate180 is not label-preserving and should not be used for augmentation.","category":"page"},{"location":"#Working-with-images-in-Julia","page":"Introduction","title":"Working with images in Julia","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Augmentor exists along other packages in the JuliaImages ecosystem. To learn how images are treated in Julia, how pixels are represented, and more, read the documentation.","category":"page"},{"location":"#Citing-Augmentor","page":"Introduction","title":"Citing Augmentor","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use Augmentor for academic research and wish to cite it, please use the following paper.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Marcus D. Bloice, Christof Stocker, and Andreas Holzinger, Augmentor: An Image Augmentation Library for Machine Learning, arXiv preprint arXiv:1708.04680, https://arxiv.org/abs/1708.04680, 2017.","category":"page"},{"location":"operations/affine/rotate/#Rotate","page":"Rotate","title":"Rotate","text":"","category":"section"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"The type Rotate defines a generic anticlockwise rotation operation around the center of the image. It is also possible to pass some abstract vector to the constructor, in which case Augmentor will randomly sample one of its elements every time the operation is applied.","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"using Augmentor\nusing ImageShow, ImageCore\nusing Random\nRandom.seed!(0)\n\nimg_in = testpattern(RGB, ratio=0.5)\nmosaicview(\n    img_in,\n\n    # deterministic rotation\n    augment(img_in, Rotate(45)),\n\n    # random rotation\n    augment(img_in, Rotate(-45:45));\n    fillvalue=colorant\"white\", nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Note that the output image size will be changed after rotation, CropNative can be particalually useful to preserve the image size.","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"mosaicview(\n    augment(img_in, Rotate(45)),\n    augment(img_in, Rotate(45) |> CropNative(axes(img_in)));\n    nrow=1, npad=10\n)","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Rotation by some special degree (e.g.,90, 180 and 270) can be handled more efficiently without interpolation. Compared to Rotate(90), it is recommended to use Rotate90 when possible. Rotate180 and Rotate270 are available, too.","category":"page"},{"location":"operations/affine/rotate/#References","page":"Rotate","title":"References","text":"","category":"section"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"Rotate\nRotate90\nRotate180\nRotate270","category":"page"},{"location":"operations/affine/rotate/#Augmentor.Rotate","page":"Rotate","title":"Augmentor.Rotate","text":"Rotate <: Augmentor.AffineOperation\n\nDescription\n\nRotate the image upwards for the given degree. This operation can only be performed as an affine transformation and will in general cause other operations of the pipeline to use their affine formulation as well (if they have one).\n\nIn contrast to the special case rotations (e.g. Rotate90, the type Rotate can describe any arbitrary number of degrees. It will always perform the rotation around the center of the image. This can be particularly useful when combining the operation with CropNative.\n\nUsage\n\nRotate(degree)\n\nArguments\n\ndegree : Real or AbstractVector of Real that denote   the rotation angle(s) in degree. If a vector is provided,   then a random element will be sampled each time the operation   is applied.\n\nSee also\n\nRotate90, Rotate180, Rotate270, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# rotate exactly 45 degree\naugment(img, Rotate(45))\n\n# rotate between 10 and 20 degree upwards\naugment(img, Rotate(10:20))\n\n# rotate one of the five specified degrees\naugment(img, Rotate([-10, -5, 0, 5, 10]))\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate90","page":"Rotate","title":"Augmentor.Rotate90","text":"Rotate90 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image upwards 90 degrees. This is a special case rotation because it can be performed very efficiently by simply rearranging the existing pixels. However, it is generally not the case that the output image will have the same size as the input image, which is something to be aware of.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate90(), 1-p=>NoOp()), where p denotes the probability of applying Rotate90 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate90()\n\nRotate90(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate180, Rotate270, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate90())\n2×2 Matrix{Int64}:\n 150   1\n 200  50\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate180","page":"Rotate","title":"Augmentor.Rotate180","text":"Rotate180 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image 180 degrees. This is a special case rotation because it can be performed very efficiently by simply rearranging the existing pixels. Furthermore, the output image will have the same dimensions as the input image.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate180(), 1-p=>NoOp()), where p denotes the probability of applying Rotate180 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate180()\n\nRotate180(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate90, Rotate270, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate180())\n2×2 Matrix{Int64}:\n   1   50\n 150  200\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/#Augmentor.Rotate270","page":"Rotate","title":"Augmentor.Rotate270","text":"Rotate270 <: Augmentor.AffineOperation\n\nDescription\n\nRotates the image upwards 270 degrees, which can also be described as rotating the image downwards 90 degrees. This is a special case rotation, because it can be performed very efficiently by simply rearranging the existing pixels. However, it is generally not the case that the output image will have the same size as the input image, which is something to be aware of.\n\nIf created using the parameter p, the operation will be lifted into Either(p=>Rotate270(), 1-p=>NoOp()), where p denotes the probability of applying Rotate270 and 1-p the probability for applying NoOp. See the documentation of Either for more information.\n\nUsage\n\nRotate270()\n\nRotate270(p)\n\nArguments\n\np::Number : Optional. Probability of applying the   operation. Must be in the interval [0,1].\n\nSee also\n\nRotate90, Rotate180, Rotate, Either, augment\n\nExamples\n\njulia> using Augmentor\n\njulia> img = [200 150; 50 1]\n2×2 Matrix{Int64}:\n 200  150\n  50    1\n\njulia> img_new = augment(img, Rotate270())\n2×2 Matrix{Int64}:\n 50  200\n  1  150\n\n\n\n\n\n","category":"type"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"","category":"page"},{"location":"operations/affine/rotate/","page":"Rotate","title":"Rotate","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"operations/size/cropratio/#CropRatio","page":"CropRatio","title":"CropRatio","text":"","category":"section"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"(Image: Source code) (Image: notebook)","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"Crop centered window to fit given aspect ratio","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"using Augmentor\nusing ImageShow, ImageCore\n\nimg_in = testpattern(RGB, ratio=0.5)\nimg_out = augment(img_in, CropRatio()) # crop out a square window\n\nmosaicview(img_in, img_out; nrow=1)","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"RCropRatio is a random version that randomly choose a crop center – not necessarily the center of the input image.","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"augment(img_in, RCropRatio())\nnothing #hide","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"(Image: )","category":"page"},{"location":"operations/size/cropratio/#Reference","page":"CropRatio","title":"Reference","text":"","category":"section"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"CropRatio\nRCropRatio","category":"page"},{"location":"operations/size/cropratio/#Augmentor.CropRatio","page":"CropRatio","title":"Augmentor.CropRatio","text":"CropRatio <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the biggest area around the center of the given image such that the output image satisfies the specified aspect ratio (i.e. width divided by height).\n\nFor example the operation CropRatio(1) would denote a crop for the biggest square around the center of the image.\n\nFor randomly placed crops take a look at RCropRatio.\n\nUsage\n\nCropRatio(ratio)\n\nCropRatio(; ratio = 1)\n\nArguments\n\nratio::Number : Optional. A number denoting the aspect   ratio. For example specifying ratio=16/9 would denote a 16:9   aspect ratio. Defaults to 1, which describes a square crop.\n\nSee also\n\nRCropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop biggest square around the image center\naugment(img, CropRatio(1))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropratio/#Augmentor.RCropRatio","page":"CropRatio","title":"Augmentor.RCropRatio","text":"RCropRatio <: Augmentor.ImageOperation\n\nDescription\n\nCrops out the biggest possible area at some random position of the given image, such that the output image satisfies the specified aspect ratio (i.e. width divided by height).\n\nFor example the operation RCropRatio(1) would denote a crop for the biggest possible square. If there is more than one such square, then one will be selected at random.\n\nUsage\n\nRCropRatio(ratio)\n\nRCropRatio(; ratio = 1)\n\nArguments\n\nratio::Number : Optional. A number denoting the aspect   ratio. For example specifying ratio=16/9 would denote a 16:9   aspect ratio. Defaults to 1, which describes a square crop.\n\nSee also\n\nRCropSize, CropRatio, CropSize, Crop, CropNative, augment\n\nExamples\n\nusing Augmentor\nimg = testpattern()\n\n# crop a randomly placed square of maxmimum size\naugment(img, RCropRatio(1))\n\n\n\n\n\n","category":"type"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"","category":"page"},{"location":"operations/size/cropratio/","page":"CropRatio","title":"CropRatio","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"}]
}
